{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "from utils.metrics import MAPE, WAPE, MAE\n",
    "from utils.dl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "lags = 32\n",
    "horizon = 8\n",
    "stride = 1\n",
    "batch_size = 256\n",
    "val_size = 0.15\n",
    "test_size = 0.0\n",
    "drop_last = False\n",
    "features = 1\n",
    "epochs = 200\n",
    "verbose = False\n",
    "\n",
    "model_params = {'num_channels': [128] * 4, 'kernel_size': 2, 'dropout': 0.25, 'output_size': horizon, 'input_size': lags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:12, 12.19s/it]Global seed set to 0\n",
      "2it [00:18,  8.76s/it]Global seed set to 0\n",
      "3it [00:24,  7.56s/it]Global seed set to 0\n",
      "4it [00:30,  6.98s/it]Global seed set to 0\n",
      "5it [00:34,  5.95s/it]Global seed set to 0\n",
      "6it [00:47,  8.19s/it]Global seed set to 0\n",
      "7it [00:57,  8.67s/it]Global seed set to 0\n",
      "8it [01:06,  9.01s/it]Global seed set to 0\n",
      "9it [01:18,  9.88s/it]Global seed set to 0\n",
      "10it [01:28,  9.89s/it]Global seed set to 0\n",
      "11it [01:46, 12.25s/it]Global seed set to 0\n",
      "12it [02:03, 13.91s/it]Global seed set to 0\n",
      "13it [02:21, 15.16s/it]Global seed set to 0\n",
      "14it [02:38, 15.48s/it]Global seed set to 0\n",
      "15it [02:57, 16.62s/it]Global seed set to 0\n",
      "16it [03:16, 17.52s/it]Global seed set to 0\n",
      "17it [03:38, 18.71s/it]Global seed set to 0\n",
      "18it [04:00, 19.72s/it]Global seed set to 0\n",
      "19it [04:21, 20.22s/it]Global seed set to 0\n",
      "20it [04:43, 20.56s/it]Global seed set to 0\n",
      "21it [05:57, 36.70s/it]Global seed set to 0\n",
      "22it [07:14, 48.84s/it]Global seed set to 0\n",
      "23it [07:59, 47.51s/it]Global seed set to 0\n",
      "24it [08:36, 21.52s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "results = []\n",
    "for time_series in tqdm(ts_iterator):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "    \n",
    "    model = Model(seed=0, device=device)\n",
    "    model.set_model(TCN, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    model.train(train_dl, epochs=epochs, print_info=verbose, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.07601827010512352, 'val': 0.09294126182794571},\n",
       " {'train': 0.03591239328185717, 'val': 0.05265411362051964},\n",
       " {'train': 0.006942708821346362, 'val': 0.005144833587110043},\n",
       " {'train': 0.009543801036973795, 'val': 0.010662950575351715},\n",
       " {'train': 0.01589103927835822, 'val': 0.013669661246240139},\n",
       " {'train': 0.026791866247852642, 'val': 0.027336619794368744},\n",
       " {'train': 0.02450627014040947, 'val': 0.036064375191926956},\n",
       " {'train': 0.0166728213429451, 'val': 0.015392552129924297},\n",
       " {'train': 0.008599746196220318, 'val': 0.0061883225571364164},\n",
       " {'train': 0.007930880784988404, 'val': 0.0070607042871415615},\n",
       " {'train': 0.047204966760343976, 'val': 0.039447009563446045},\n",
       " {'train': 0.034146616235375404, 'val': 0.021188664250075817},\n",
       " {'train': 0.03233239323728614, 'val': 0.032122411765158176},\n",
       " {'train': 0.011525885667651892, 'val': 0.006635635392740369},\n",
       " {'train': 0.017489527072757482, 'val': 0.01032670121639967},\n",
       " {'train': 0.03790958225727081, 'val': 0.027314666658639908},\n",
       " {'train': 0.027332772585478695, 'val': 0.021849971264600754},\n",
       " {'train': 0.006604286164722659, 'val': 0.006474820431321859},\n",
       " {'train': 0.017669459550895474, 'val': 0.017051586881279945},\n",
       " {'train': 0.009044607804918831, 'val': 0.005583102349191904},\n",
       " {'train': 0.014820406041843327, 'val': 0.007273129387093442},\n",
       " {'train': 0.008644364983774721, 'val': 0.006696137308608741},\n",
       " {'train': 0.02172178588807583, 'val': 0.028981235809624195},\n",
       " {'train': 0.01590262363223653, 'val': 0.00881898240186274}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\pure_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with QuantGAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDataLoader:\n",
    "    def __init__(self, *dls):\n",
    "        self.dls = dls\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(map(len, self.dls))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for dl in self.dls:\n",
    "            for v in dl:\n",
    "                yield v\n",
    "\n",
    "\n",
    "def train_synth(synthetic_path):\n",
    "    ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "    epochs = 2\n",
    "\n",
    "    results = []\n",
    "    for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "        train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                                val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "\n",
    "        synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "        synth_dls = []\n",
    "        for i in range(synth_time_series.shape[0]):\n",
    "            synth_dl, *_ = create_ts_dl(synth_time_series[i].reshape(- 1, 1), synth_time_series[i].flatten(), lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                batch_size=batch_size, device=device, data_preprocess=None,\\\n",
    "                                                val_size=0, test_size=0, drop_last=drop_last)\n",
    "            synth_dls.append(synth_dl)\n",
    "        \n",
    "        model = Model(seed=0, device=device)\n",
    "        model.set_model(TCN, **model_params)\n",
    "        optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "        model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "        model.set_criterion(MAE)\n",
    "\n",
    "        # cdl = CombinedDataLoader(train_dl, *synth_dls)\n",
    "        # only synth data\n",
    "        cdl = CombinedDataLoader(*synth_dls)\n",
    "        model.train(cdl, epochs=epochs, print_info=verbose, agg_loss=\"mean\")\n",
    "        results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "        del model, train_dl, val_dl, test_dl\n",
    "        torch.cuda.empty_cache()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.10775789991021156, 'val': 0.08761278539896011},\n",
       " {'train': 0.04027101770043373, 'val': 0.05313824117183685},\n",
       " {'train': 0.007714773993939161, 'val': 0.0056333988904953},\n",
       " {'train': 0.010017184230188528, 'val': 0.010736174881458282},\n",
       " {'train': 0.016770757269114256, 'val': 0.012860503979027271},\n",
       " {'train': 0.029067910586794216, 'val': 0.02728160098195076},\n",
       " {'train': 0.02904174029827118, 'val': 0.03444803133606911},\n",
       " {'train': 0.017426739819347857, 'val': 0.015151316300034523},\n",
       " {'train': 0.009081647576143345, 'val': 0.006351890275254846},\n",
       " {'train': 0.008119670208543539, 'val': 0.006900529842823744},\n",
       " {'train': 0.053747433341211744, 'val': 0.03965535759925842},\n",
       " {'train': 0.03879339247941971, 'val': 0.020823094062507153},\n",
       " {'train': 0.03564218493799368, 'val': 0.03145353216677904},\n",
       " {'train': 0.01201541442424059, 'val': 0.0064820037223398685},\n",
       " {'train': 0.018960770405828952, 'val': 0.010626457631587982},\n",
       " {'train': 0.04312667790800333, 'val': 0.02642847504466772},\n",
       " {'train': 0.031129577789794315, 'val': 0.021876540035009384},\n",
       " {'train': 0.006706808524375612, 'val': 0.006478616269305348},\n",
       " {'train': 0.01835200266743248, 'val': 0.016732441727072},\n",
       " {'train': 0.009250371886247938, 'val': 0.005525956396013498},\n",
       " {'train': 0.015541288266448598, 'val': 0.007757742223995072},\n",
       " {'train': 0.009442721283994615, 'val': 0.00695493578677997},\n",
       " {'train': 0.023594400481037472, 'val': 0.028532180935144424},\n",
       " {'train': 0.018353596746333335, 'val': 0.008714858791790903}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/QuantGAN/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\QuantGAN_synth_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with FourierFlow synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:34, 34.76s/it]Global seed set to 0\n",
      "2it [00:55, 26.41s/it]Global seed set to 0\n",
      "3it [01:16, 24.14s/it]Global seed set to 0\n",
      "4it [01:39, 23.66s/it]Global seed set to 0\n",
      "5it [02:00, 22.46s/it]Global seed set to 0\n",
      "6it [02:21, 22.06s/it]Global seed set to 0\n",
      "7it [02:43, 22.16s/it]Global seed set to 0\n",
      "8it [03:06, 22.28s/it]Global seed set to 0\n",
      "9it [03:27, 21.92s/it]Global seed set to 0\n",
      "10it [03:47, 21.52s/it]Global seed set to 0\n",
      "11it [04:07, 20.80s/it]Global seed set to 0\n",
      "12it [04:26, 20.46s/it]Global seed set to 0\n",
      "13it [04:47, 20.63s/it]Global seed set to 0\n",
      "14it [05:07, 20.27s/it]Global seed set to 0\n",
      "15it [05:27, 20.11s/it]Global seed set to 0\n",
      "16it [05:46, 19.99s/it]Global seed set to 0\n",
      "17it [06:06, 19.81s/it]Global seed set to 0\n",
      "18it [06:27, 20.25s/it]Global seed set to 0\n",
      "19it [06:46, 20.04s/it]Global seed set to 0\n",
      "20it [07:06, 19.98s/it]Global seed set to 0\n",
      "21it [07:27, 20.12s/it]Global seed set to 0\n",
      "22it [07:47, 20.21s/it]Global seed set to 0\n",
      "23it [08:07, 20.16s/it]Global seed set to 0\n",
      "24it [08:28, 21.17s/it]\n"
     ]
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/FourierFlow/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\FourierFlow_synth_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with RealNVP synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:25, 25.05s/it]Global seed set to 0\n",
      "2it [00:44, 21.77s/it]Global seed set to 0\n",
      "3it [01:04, 20.89s/it]Global seed set to 0\n",
      "4it [01:26, 21.49s/it]Global seed set to 0\n",
      "5it [01:48, 21.63s/it]Global seed set to 0\n",
      "6it [02:12, 22.22s/it]Global seed set to 0\n",
      "7it [02:36, 22.82s/it]Global seed set to 0\n",
      "8it [02:57, 22.49s/it]Global seed set to 0\n",
      "9it [03:19, 22.25s/it]Global seed set to 0\n",
      "10it [03:40, 21.81s/it]Global seed set to 0\n",
      "11it [04:01, 21.66s/it]Global seed set to 0\n",
      "12it [04:22, 21.29s/it]Global seed set to 0\n",
      "13it [04:44, 21.48s/it]Global seed set to 0\n",
      "14it [05:04, 21.27s/it]Global seed set to 0\n",
      "15it [05:23, 20.54s/it]Global seed set to 0\n",
      "16it [05:40, 19.39s/it]Global seed set to 0\n",
      "17it [05:57, 18.60s/it]Global seed set to 0\n",
      "18it [06:15, 18.39s/it]Global seed set to 0\n",
      "19it [06:34, 18.60s/it]Global seed set to 0\n",
      "20it [06:53, 18.94s/it]Global seed set to 0\n",
      "21it [07:10, 18.35s/it]Global seed set to 0\n",
      "22it [07:29, 18.55s/it]Global seed set to 0\n",
      "23it [07:48, 18.48s/it]Global seed set to 0\n",
      "24it [08:06, 20.28s/it]\n"
     ]
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/RealNVP/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\RealNVP_synth_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with TTS GAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:28, 28.92s/it]Global seed set to 0\n",
      "2it [01:04, 32.71s/it]Global seed set to 0\n",
      "3it [01:38, 33.39s/it]Global seed set to 0\n",
      "4it [02:10, 32.88s/it]Global seed set to 0\n",
      "5it [02:41, 32.23s/it]Global seed set to 0\n",
      "6it [03:09, 30.70s/it]Global seed set to 0\n",
      "7it [03:35, 29.30s/it]Global seed set to 0\n",
      "8it [04:02, 28.34s/it]Global seed set to 0\n",
      "9it [04:27, 27.54s/it]Global seed set to 0\n",
      "10it [04:53, 27.05s/it]Global seed set to 0\n",
      "11it [05:20, 26.83s/it]Global seed set to 0\n",
      "12it [05:46, 26.55s/it]Global seed set to 0\n",
      "13it [06:12, 26.37s/it]Global seed set to 0\n",
      "14it [06:37, 26.21s/it]Global seed set to 0\n",
      "15it [07:04, 26.43s/it]Global seed set to 0\n",
      "16it [07:30, 26.32s/it]Global seed set to 0\n",
      "17it [07:57, 26.29s/it]Global seed set to 0\n",
      "18it [08:23, 26.41s/it]Global seed set to 0\n",
      "19it [08:50, 26.38s/it]Global seed set to 0\n",
      "20it [09:16, 26.37s/it]Global seed set to 0\n",
      "21it [09:43, 26.55s/it]Global seed set to 0\n",
      "22it [10:10, 26.68s/it]Global seed set to 0\n",
      "23it [10:36, 26.60s/it]Global seed set to 0\n",
      "24it [11:03, 27.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.1234881691634655, 'val': 0.11661145836114883},\n",
       " {'train': 0.0406411848962307, 'val': 0.05121273919939995},\n",
       " {'train': 0.007865304437776407, 'val': 0.0061461441218853},\n",
       " {'train': 0.010188820927093426, 'val': 0.010907528921961784},\n",
       " {'train': 0.04357287473976612, 'val': 0.04281071946024895},\n",
       " {'train': 0.02910853922367096, 'val': 0.027308590710163116},\n",
       " {'train': 0.02897317223250866, 'val': 0.03419254347681999},\n",
       " {'train': 0.017463923431932926, 'val': 0.015027855522930622},\n",
       " {'train': 0.009026645217090845, 'val': 0.006393409334123135},\n",
       " {'train': 0.008107946626842022, 'val': 0.006907070055603981},\n",
       " {'train': 0.05294864748915037, 'val': 0.038608504459261894},\n",
       " {'train': 0.03836228201786677, 'val': 0.02062815148383379},\n",
       " {'train': 0.03631164340509309, 'val': 0.03271069750189781},\n",
       " {'train': 0.011803480563685298, 'val': 0.006573209073394537},\n",
       " {'train': 0.01886085979640484, 'val': 0.010584883391857147},\n",
       " {'train': 0.04373375661671162, 'val': 0.026596336625516415},\n",
       " {'train': 0.03082691200754859, 'val': 0.02194317616522312},\n",
       " {'train': 0.006949132731692357, 'val': 0.006657027872279286},\n",
       " {'train': 0.018449521708217533, 'val': 0.016910328064113855},\n",
       " {'train': 0.009394799232144247, 'val': 0.005780534353107214},\n",
       " {'train': 0.685381260357405, 'val': 0.6831227455820356},\n",
       " {'train': 0.009073577728122473, 'val': 0.006857206695713103},\n",
       " {'train': 0.024358115928328556, 'val': 0.029007867444306612},\n",
       " {'train': 0.01851319423631618, 'val': 0.008624328067526221}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/TTS_GAN/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\TTS_GAN_synth_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
