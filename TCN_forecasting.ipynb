{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "from utils.metrics import MAPE, WAPE, MAE\n",
    "from utils.dl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "lags = 32\n",
    "horizon = 8\n",
    "stride = 1\n",
    "batch_size = 256\n",
    "val_size = 0.15\n",
    "test_size = 0.0\n",
    "drop_last = False\n",
    "features = 1\n",
    "epochs = 200\n",
    "verbose = False\n",
    "\n",
    "model_params = {'num_channels': [128] * 4, 'kernel_size': 2, 'dropout': 0.25, 'output_size': horizon, 'input_size': lags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:12, 12.19s/it]Global seed set to 0\n",
      "2it [00:18,  8.76s/it]Global seed set to 0\n",
      "3it [00:24,  7.56s/it]Global seed set to 0\n",
      "4it [00:30,  6.98s/it]Global seed set to 0\n",
      "5it [00:34,  5.95s/it]Global seed set to 0\n",
      "6it [00:47,  8.19s/it]Global seed set to 0\n",
      "7it [00:57,  8.67s/it]Global seed set to 0\n",
      "8it [01:06,  9.01s/it]Global seed set to 0\n",
      "9it [01:18,  9.88s/it]Global seed set to 0\n",
      "10it [01:28,  9.89s/it]Global seed set to 0\n",
      "11it [01:46, 12.25s/it]Global seed set to 0\n",
      "12it [02:03, 13.91s/it]Global seed set to 0\n",
      "13it [02:21, 15.16s/it]Global seed set to 0\n",
      "14it [02:38, 15.48s/it]Global seed set to 0\n",
      "15it [02:57, 16.62s/it]Global seed set to 0\n",
      "16it [03:16, 17.52s/it]Global seed set to 0\n",
      "17it [03:38, 18.71s/it]Global seed set to 0\n",
      "18it [04:00, 19.72s/it]Global seed set to 0\n",
      "19it [04:21, 20.22s/it]Global seed set to 0\n",
      "20it [04:43, 20.56s/it]Global seed set to 0\n",
      "21it [05:57, 36.70s/it]Global seed set to 0\n",
      "22it [07:14, 48.84s/it]Global seed set to 0\n",
      "23it [07:59, 47.51s/it]Global seed set to 0\n",
      "24it [08:36, 21.52s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "results = []\n",
    "for time_series in tqdm(ts_iterator):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "    \n",
    "    model = Model(seed=0, device=device)\n",
    "    model.set_model(TCN, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    model.train(train_dl, epochs=epochs, print_info=verbose, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.07601827010512352, 'val': 0.09294126182794571},\n",
       " {'train': 0.03591239328185717, 'val': 0.05265411362051964},\n",
       " {'train': 0.006942708821346362, 'val': 0.005144833587110043},\n",
       " {'train': 0.009543801036973795, 'val': 0.010662950575351715},\n",
       " {'train': 0.01589103927835822, 'val': 0.013669661246240139},\n",
       " {'train': 0.026791866247852642, 'val': 0.027336619794368744},\n",
       " {'train': 0.02450627014040947, 'val': 0.036064375191926956},\n",
       " {'train': 0.0166728213429451, 'val': 0.015392552129924297},\n",
       " {'train': 0.008599746196220318, 'val': 0.0061883225571364164},\n",
       " {'train': 0.007930880784988404, 'val': 0.0070607042871415615},\n",
       " {'train': 0.047204966760343976, 'val': 0.039447009563446045},\n",
       " {'train': 0.034146616235375404, 'val': 0.021188664250075817},\n",
       " {'train': 0.03233239323728614, 'val': 0.032122411765158176},\n",
       " {'train': 0.011525885667651892, 'val': 0.006635635392740369},\n",
       " {'train': 0.017489527072757482, 'val': 0.01032670121639967},\n",
       " {'train': 0.03790958225727081, 'val': 0.027314666658639908},\n",
       " {'train': 0.027332772585478695, 'val': 0.021849971264600754},\n",
       " {'train': 0.006604286164722659, 'val': 0.006474820431321859},\n",
       " {'train': 0.017669459550895474, 'val': 0.017051586881279945},\n",
       " {'train': 0.009044607804918831, 'val': 0.005583102349191904},\n",
       " {'train': 0.014820406041843327, 'val': 0.007273129387093442},\n",
       " {'train': 0.008644364983774721, 'val': 0.006696137308608741},\n",
       " {'train': 0.02172178588807583, 'val': 0.028981235809624195},\n",
       " {'train': 0.01590262363223653, 'val': 0.00881898240186274}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\pure_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with QuantGAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_path = f\"{dataset_path}synthetic/QuantGAN/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDataLoader:\n",
    "    def __init__(self, *dls):\n",
    "        self.dls = dls\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(map(len, self.dls))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for dl in self.dls:\n",
    "            for v in dl:\n",
    "                yield v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:33, 33.45s/it]Global seed set to 0\n",
      "2it [01:02, 31.03s/it]Global seed set to 0\n",
      "3it [01:31, 29.91s/it]Global seed set to 0\n",
      "4it [01:59, 29.26s/it]Global seed set to 0\n",
      "5it [02:26, 28.48s/it]Global seed set to 0\n",
      "6it [02:54, 28.27s/it]Global seed set to 0\n",
      "7it [03:22, 28.21s/it]Global seed set to 0\n",
      "8it [03:51, 28.26s/it]Global seed set to 0\n",
      "9it [04:20, 28.53s/it]Global seed set to 0\n",
      "10it [04:49, 28.70s/it]Global seed set to 0\n",
      "11it [05:13, 27.28s/it]Global seed set to 0\n",
      "12it [05:42, 27.72s/it]Global seed set to 0\n",
      "13it [06:10, 28.02s/it]Global seed set to 0\n",
      "14it [06:39, 28.30s/it]Global seed set to 0\n",
      "15it [07:08, 28.40s/it]Global seed set to 0\n",
      "16it [07:36, 28.48s/it]Global seed set to 0\n",
      "17it [08:06, 28.73s/it]Global seed set to 0\n",
      "18it [08:35, 28.81s/it]Global seed set to 0\n",
      "19it [09:04, 28.83s/it]Global seed set to 0\n",
      "20it [09:37, 30.12s/it]Global seed set to 0\n",
      "21it [10:05, 29.53s/it]Global seed set to 0\n",
      "22it [10:35, 29.76s/it]Global seed set to 0\n",
      "23it [11:05, 29.71s/it]Global seed set to 0\n",
      "24it [11:36, 29.03s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "epochs = 2\n",
    "\n",
    "results = []\n",
    "for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "\n",
    "    synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "    synth_dls = []\n",
    "    for i in range(synth_time_series.shape[0]):\n",
    "        synth_dl, *_ = create_ts_dl(synth_time_series[i].reshape(127, 1), synth_time_series[i], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=None,\\\n",
    "                                            val_size=0, test_size=0, drop_last=drop_last)\n",
    "        synth_dls.append(synth_dl)\n",
    "    \n",
    "    model = Model(seed=0, device=device)\n",
    "    model.set_model(TCN, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    # cdl = CombinedDataLoader(train_dl, *synth_dls)\n",
    "    # only synth data\n",
    "    cdl = CombinedDataLoader(*synth_dls)\n",
    "    model.train(cdl, epochs=epochs, print_info=verbose, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.10775789991021156, 'val': 0.08761278539896011},\n",
       " {'train': 0.04027101770043373, 'val': 0.05313824117183685},\n",
       " {'train': 0.007714773993939161, 'val': 0.0056333988904953},\n",
       " {'train': 0.010017184230188528, 'val': 0.010736174881458282},\n",
       " {'train': 0.016770757269114256, 'val': 0.012860503979027271},\n",
       " {'train': 0.029067910586794216, 'val': 0.02728160098195076},\n",
       " {'train': 0.02904174029827118, 'val': 0.03444803133606911},\n",
       " {'train': 0.017426739819347857, 'val': 0.015151316300034523},\n",
       " {'train': 0.009081647576143345, 'val': 0.006351890275254846},\n",
       " {'train': 0.008119670208543539, 'val': 0.006900529842823744},\n",
       " {'train': 0.053747433341211744, 'val': 0.03965535759925842},\n",
       " {'train': 0.03879339247941971, 'val': 0.020823094062507153},\n",
       " {'train': 0.03564218493799368, 'val': 0.03145353216677904},\n",
       " {'train': 0.01201541442424059, 'val': 0.0064820037223398685},\n",
       " {'train': 0.018960770405828952, 'val': 0.010626457631587982},\n",
       " {'train': 0.04312667790800333, 'val': 0.02642847504466772},\n",
       " {'train': 0.031129577789794315, 'val': 0.021876540035009384},\n",
       " {'train': 0.006706808524375612, 'val': 0.006478616269305348},\n",
       " {'train': 0.01835200266743248, 'val': 0.016732441727072},\n",
       " {'train': 0.009250371886247938, 'val': 0.005525956396013498},\n",
       " {'train': 0.015541288266448598, 'val': 0.007757742223995072},\n",
       " {'train': 0.009442721283994615, 'val': 0.00695493578677997},\n",
       " {'train': 0.023594400481037472, 'val': 0.028532180935144424},\n",
       " {'train': 0.018353596746333335, 'val': 0.008714858791790903}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\QuantGAN_synth_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with FourierFlow synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_path = f\"{dataset_path}synthetic/FourierFlow/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:34, 34.76s/it]Global seed set to 0\n",
      "2it [00:55, 26.41s/it]Global seed set to 0\n",
      "3it [01:16, 24.14s/it]Global seed set to 0\n",
      "4it [01:39, 23.66s/it]Global seed set to 0\n",
      "5it [02:00, 22.46s/it]Global seed set to 0\n",
      "6it [02:21, 22.06s/it]Global seed set to 0\n",
      "7it [02:43, 22.16s/it]Global seed set to 0\n",
      "8it [03:06, 22.28s/it]Global seed set to 0\n",
      "9it [03:27, 21.92s/it]Global seed set to 0\n",
      "10it [03:47, 21.52s/it]Global seed set to 0\n",
      "11it [04:07, 20.80s/it]Global seed set to 0\n",
      "12it [04:26, 20.46s/it]Global seed set to 0\n",
      "13it [04:47, 20.63s/it]Global seed set to 0\n",
      "14it [05:07, 20.27s/it]Global seed set to 0\n",
      "15it [05:27, 20.11s/it]Global seed set to 0\n",
      "16it [05:46, 19.99s/it]Global seed set to 0\n",
      "17it [06:06, 19.81s/it]Global seed set to 0\n",
      "18it [06:27, 20.25s/it]Global seed set to 0\n",
      "19it [06:46, 20.04s/it]Global seed set to 0\n",
      "20it [07:06, 19.98s/it]Global seed set to 0\n",
      "21it [07:27, 20.12s/it]Global seed set to 0\n",
      "22it [07:47, 20.21s/it]Global seed set to 0\n",
      "23it [08:07, 20.16s/it]Global seed set to 0\n",
      "24it [08:28, 21.17s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "epochs = 2\n",
    "\n",
    "results = []\n",
    "for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "\n",
    "    synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "    synth_dls = []\n",
    "    for i in range(synth_time_series.shape[0]):\n",
    "        synth_dl, *_ = create_ts_dl(synth_time_series[i].reshape(- 1, 1), synth_time_series[i], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=None,\\\n",
    "                                            val_size=0, test_size=0, drop_last=drop_last)\n",
    "        synth_dls.append(synth_dl)\n",
    "    \n",
    "    model = Model(seed=0, device=device)\n",
    "    model.set_model(TCN, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    # only synth data\n",
    "    cdl = CombinedDataLoader(*synth_dls)\n",
    "    model.train(cdl, epochs=epochs, print_info=verbose, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.04299928620457649, 'val': 0.09553902596235275},\n",
       " {'train': 0.034737035632133484, 'val': 0.0577583909034729},\n",
       " {'train': 0.007313713897019625, 'val': 0.0054608541540801525},\n",
       " {'train': 0.010091571447749933, 'val': 0.01081530936062336},\n",
       " {'train': 0.0158067112788558, 'val': 0.0141794728115201},\n",
       " {'train': 0.027944813172022503, 'val': 0.02861202508211136},\n",
       " {'train': 0.027533545345067977, 'val': 0.037445973604917526},\n",
       " {'train': 0.016803331300616266, 'val': 0.015673236921429634},\n",
       " {'train': 0.009009471939255794, 'val': 0.006061585154384375},\n",
       " {'train': 0.008441495522856713, 'val': 0.007223269436508417},\n",
       " {'train': 0.0509502746992641, 'val': 0.04000464268028736},\n",
       " {'train': 0.035812276105086006, 'val': 0.020886201411485672},\n",
       " {'train': 0.03362286960085233, 'val': 0.03203243296593428},\n",
       " {'train': 0.011749354074709117, 'val': 0.006637847051024437},\n",
       " {'train': 0.01852165637537837, 'val': 0.010446077212691307},\n",
       " {'train': 0.04027140736579895, 'val': 0.027284150943160057},\n",
       " {'train': 0.028827551075003365, 'val': 0.021807612851262093},\n",
       " {'train': 0.006775990170849996, 'val': 0.006652580574154854},\n",
       " {'train': 0.01833493279462511, 'val': 0.01733215991407633},\n",
       " {'train': 0.009689963338049975, 'val': 0.0059223363641649485},\n",
       " {'train': 0.015268723590691624, 'val': 0.007321483987782683},\n",
       " {'train': 0.008999388432130218, 'val': 0.006780782307032496},\n",
       " {'train': 0.023337637195768562, 'val': 0.028543131425976753},\n",
       " {'train': 0.017383959585506665, 'val': 0.008791709900833666}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\FourierFlow_synth_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with RealNVP synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:25, 25.05s/it]Global seed set to 0\n",
      "2it [00:44, 21.77s/it]Global seed set to 0\n",
      "3it [01:04, 20.89s/it]Global seed set to 0\n",
      "4it [01:26, 21.49s/it]Global seed set to 0\n",
      "5it [01:48, 21.63s/it]Global seed set to 0\n",
      "6it [02:12, 22.22s/it]Global seed set to 0\n",
      "7it [02:36, 22.82s/it]Global seed set to 0\n",
      "8it [02:57, 22.49s/it]Global seed set to 0\n",
      "9it [03:19, 22.25s/it]Global seed set to 0\n",
      "10it [03:40, 21.81s/it]Global seed set to 0\n",
      "11it [04:01, 21.66s/it]Global seed set to 0\n",
      "12it [04:22, 21.29s/it]Global seed set to 0\n",
      "13it [04:44, 21.48s/it]Global seed set to 0\n",
      "14it [05:04, 21.27s/it]Global seed set to 0\n",
      "15it [05:23, 20.54s/it]Global seed set to 0\n",
      "16it [05:40, 19.39s/it]Global seed set to 0\n",
      "17it [05:57, 18.60s/it]Global seed set to 0\n",
      "18it [06:15, 18.39s/it]Global seed set to 0\n",
      "19it [06:34, 18.60s/it]Global seed set to 0\n",
      "20it [06:53, 18.94s/it]Global seed set to 0\n",
      "21it [07:10, 18.35s/it]Global seed set to 0\n",
      "22it [07:29, 18.55s/it]Global seed set to 0\n",
      "23it [07:48, 18.48s/it]Global seed set to 0\n",
      "24it [08:06, 20.28s/it]\n"
     ]
    }
   ],
   "source": [
    "synthetic_path = f\"{dataset_path}synthetic/RealNVP/\"\n",
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "epochs = 2\n",
    "\n",
    "results = []\n",
    "for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "\n",
    "    synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "    synth_dls = []\n",
    "    for i in range(synth_time_series.shape[0]):\n",
    "        synth_dl, *_ = create_ts_dl(synth_time_series[i].reshape(- 1, 1), synth_time_series[i], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=None,\\\n",
    "                                            val_size=0, test_size=0, drop_last=drop_last)\n",
    "        synth_dls.append(synth_dl)\n",
    "    \n",
    "    model = Model(seed=0, device=device)\n",
    "    model.set_model(TCN, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    # only synth data\n",
    "    cdl = CombinedDataLoader(*synth_dls)\n",
    "    model.train(cdl, epochs=epochs, print_info=verbose, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.022699295543134212, 'val': 0.11058970540761948},\n",
       " {'train': 0.031208307792743046, 'val': 0.05794366076588631},\n",
       " {'train': 0.0069389975008865195, 'val': 0.0051651690155267715},\n",
       " {'train': 0.009290863604595264, 'val': 0.010841844603419304},\n",
       " {'train': 0.014406627044081688, 'val': 0.013607817701995373},\n",
       " {'train': 0.02649128871659438, 'val': 0.027409205213189125},\n",
       " {'train': 0.025554822757840157, 'val': 0.03524057939648628},\n",
       " {'train': 0.016241544485092164, 'val': 0.015404561534523964},\n",
       " {'train': 0.00858282313371698, 'val': 0.006164876976981759},\n",
       " {'train': 0.007948750723153352, 'val': 0.007010172121226788},\n",
       " {'train': 0.04852983603874842, 'val': 0.03915001079440117},\n",
       " {'train': 0.034994653736551605, 'val': 0.021006189286708832},\n",
       " {'train': 0.03291084306935469, 'val': 0.031834215857088566},\n",
       " {'train': 0.011516043683513999, 'val': 0.00660939491353929},\n",
       " {'train': 0.017801154404878616, 'val': 0.010262904688715935},\n",
       " {'train': 0.03930122163146734, 'val': 0.027040889486670494},\n",
       " {'train': 0.028210218487815422, 'val': 0.021695422939956188},\n",
       " {'train': 0.006635115100917491, 'val': 0.006471159402281046},\n",
       " {'train': 0.017997402189807457, 'val': 0.016941905487328768},\n",
       " {'train': 0.00915731176395308, 'val': 0.0055889952927827835},\n",
       " {'train': 0.014916394763675175, 'val': 0.007251593616924116},\n",
       " {'train': 0.008736368513200431, 'val': 0.006701738864649087},\n",
       " {'train': 0.02310092322042455, 'val': 0.028321902733296156},\n",
       " {'train': 0.01714650490076134, 'val': 0.008774091955274343}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\RealNVP_synth_TCN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
