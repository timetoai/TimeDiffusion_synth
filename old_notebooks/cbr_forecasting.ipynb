{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_error as MAE, mean_absolute_percentage_error as MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 32\n",
    "horizon = 8\n",
    "stride = 1\n",
    "val_size = 0.0\n",
    "test_size = 0.3\n",
    "features = 1\n",
    "\n",
    "model_params = {\"silent\": True, \"random_seed\": 13, 'loss_function': 'MultiRMSE',  'eval_metric': 'MultiRMSE', \"iterations\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [01:28,  3.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.4551696792367407, 'val': 0.460470602310324},\n",
       " {'train': 0.5409159536326564, 'val': 0.9238519972039024},\n",
       " {'train': 0.6099430898749105, 'val': 0.5668185352340493},\n",
       " {'train': 0.6302642027246494, 'val': 0.6036037557162195},\n",
       " {'train': 0.550001437018047, 'val': 0.46924459526660023},\n",
       " {'train': 0.6109781667128318, 'val': 0.6904009339140769},\n",
       " {'train': 0.5856537384808643, 'val': 0.8353120593180834},\n",
       " {'train': 0.5508834626020176, 'val': 0.48106388387647303},\n",
       " {'train': 0.69311364731957, 'val': 0.629294993384431},\n",
       " {'train': 0.6861136063149611, 'val': 0.7566039204390955},\n",
       " {'train': 0.6121696371455706, 'val': 0.6331751517173319},\n",
       " {'train': 0.5661686622992493, 'val': 0.42644868716920525},\n",
       " {'train': 0.5439640073507215, 'val': 0.565654813393387},\n",
       " {'train': 0.6468779767267319, 'val': 0.45658979849977355},\n",
       " {'train': 0.6395846526366398, 'val': 0.4664283248267977},\n",
       " {'train': 0.5569917316854089, 'val': 0.39352750212932663},\n",
       " {'train': 0.5989970473851234, 'val': 0.703203902479455},\n",
       " {'train': 0.5751669524971424, 'val': 0.47628083650751074},\n",
       " {'train': 0.6511023525118309, 'val': 0.60088112250633},\n",
       " {'train': 0.6319015185328567, 'val': 0.418159779330702},\n",
       " {'train': 0.40508894411967555, 'val': 0.20609888037861832},\n",
       " {'train': 0.6049325068191428, 'val': 0.5087924238667741},\n",
       " {'train': 0.6961176064893092, 'val': 0.6728913186911267},\n",
       " {'train': 0.48094284391521197, 'val': 0.3234947730970191}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "results = []\n",
    "for time_series in tqdm(ts_iterator):\n",
    "    (X_train, y_train), _, (X_test, y_test), X_scaler, y_scaler = create_ts(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            data_preprocess=(\"log_returns\", \"normalize\"),\\\n",
    "                                            val_size=val_size, test_size=test_size)\n",
    "    X_train, X_test = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_test))\n",
    "    \n",
    "    model = CatBoostRegressor(**model_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    results.append(MAE(y_test, model.predict(X_test)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\pure_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with QuantGAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_synth(synthetic_path):\n",
    "    ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "    results = []\n",
    "    for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "        synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "        scaler = DimUniversalStandardScaler()\n",
    "        synth_time_series = scaler.fit_transform(synth_time_series)\n",
    "        X_synth, y_synth = [], []\n",
    "        for i in range(synth_time_series.shape[0]):\n",
    "            (X, y), *_ = create_ts(synth_time_series[i].reshape(- 1, 1), synth_time_series[i].flatten(), lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                data_preprocess=(None,), val_size=0, test_size=0)\n",
    "            X_synth.append(X)\n",
    "            y_synth.append(y)\n",
    "\n",
    "        # using train and synth data\n",
    "        # X_train = np.row_stack((X_train, *X_synth))\n",
    "        # y_train = np.row_stack((y_train, *y_synth))\n",
    "        # using only synth data\n",
    "        X_synth = np.row_stack(X_synth)\n",
    "        y_synth = np.row_stack(y_synth)\n",
    "\n",
    "        \n",
    "        (X_train, y_train), _, (X_test, y_test), *_ = create_ts(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                data_preprocess=(\"log_returns\", \"normalize\"), val_size=val_size, test_size=test_size, scaler=scaler)\n",
    "        X_train, X_test, X_synth = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_test, X_synth))\n",
    "        \n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(X_synth, y_synth)\n",
    "        results.append({\"train\": MAE(y_train, model.predict(X_train)), \"test\": MAE(y_test, model.predict(X_test))})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:45, 14.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.5705976005529405, 'val': 0.495936914983925},\n",
       " {'train': 0.7906638254047553, 'val': 1.2479540067632215},\n",
       " {'train': 0.6865303624407124, 'val': 0.5589616515091492},\n",
       " {'train': 0.7183084484047211, 'val': 0.5920065674247412},\n",
       " {'train': 0.64538927090309, 'val': 0.4586054053018275},\n",
       " {'train': 0.7170679586561128, 'val': 0.7526422049527296},\n",
       " {'train': 0.7233984971455265, 'val': 0.9544777322826088},\n",
       " {'train': 0.6587851940367666, 'val': 0.531267858974961},\n",
       " {'train': 0.7518214702351398, 'val': 0.6440745649911239},\n",
       " {'train': 0.7416300429983089, 'val': 0.7444720302010077},\n",
       " {'train': 0.554201114247848, 'val': 0.5453133001746481},\n",
       " {'train': 0.6477365802668988, 'val': 0.4620950986109732},\n",
       " {'train': 0.6566237313754806, 'val': 0.650461006612295},\n",
       " {'train': 0.6681783980748504, 'val': 0.4489827860531509},\n",
       " {'train': 0.6808225869697382, 'val': 0.4732200046602029},\n",
       " {'train': 0.602612144084566, 'val': 0.4076271493397299},\n",
       " {'train': 0.6549016919492303, 'val': 0.7335707730095424},\n",
       " {'train': 0.6762183206161326, 'val': 0.5347153713233067},\n",
       " {'train': 0.700218234388386, 'val': 0.6161000091948627},\n",
       " {'train': 0.6873995468928347, 'val': 0.43388317242769614},\n",
       " {'train': 0.23414123980959628, 'val': 0.11952708652504015},\n",
       " {'train': 0.6637935361230641, 'val': 0.5552635170077036},\n",
       " {'train': 0.7407504264093686, 'val': 0.6992894731581479},\n",
       " {'train': 0.5869664906817742, 'val': 0.3742695078924564}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/QuantGAN/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\QuantGAN_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with FourierFlow synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:18, 15.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.39266954399588516, 'val': 0.3725091337596058},\n",
       " {'train': 0.5327169270857809, 'val': 0.9044217976217865},\n",
       " {'train': 0.5762583844881217, 'val': 0.5119876248562301},\n",
       " {'train': 0.588566339601027, 'val': 0.5350551802569065},\n",
       " {'train': 0.5314240151607013, 'val': 0.40696223602121684},\n",
       " {'train': 0.5733070050802087, 'val': 0.6320379544444451},\n",
       " {'train': 0.5414358874210758, 'val': 0.771274521519554},\n",
       " {'train': 0.5308209750931543, 'val': 0.4514637872366499},\n",
       " {'train': 0.6510222534537909, 'val': 0.5836922349174817},\n",
       " {'train': 0.6157591029340191, 'val': 0.6641309797338112},\n",
       " {'train': 0.588341715310258, 'val': 0.6044140241837402},\n",
       " {'train': 0.5411490473749854, 'val': 0.41200672511994774},\n",
       " {'train': 0.5292334388927556, 'val': 0.5530587776994584},\n",
       " {'train': 0.5804922537621942, 'val': 0.4188585753794068},\n",
       " {'train': 0.5761994349605177, 'val': 0.4273958347888962},\n",
       " {'train': 0.5371483760567111, 'val': 0.3801038815022171},\n",
       " {'train': 0.5511079375414307, 'val': 0.629519997618488},\n",
       " {'train': 0.5180406757918354, 'val': 0.43483315091008323},\n",
       " {'train': 0.6155737948781819, 'val': 0.5600560368995451},\n",
       " {'train': 0.5588188436298979, 'val': 0.37966851316326067},\n",
       " {'train': 0.300235459831628, 'val': 0.15171347828552556},\n",
       " {'train': 0.4782814058195393, 'val': 0.3922727419377377},\n",
       " {'train': 0.6752558849142565, 'val': 0.6531928859147603},\n",
       " {'train': 0.442013525593255, 'val': 0.3100025046946324}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/FourierFlow/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\FourierFlow_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with RealNVP synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:00, 15.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.4192691074775543, 'val': 0.4776051485443943},\n",
       " {'train': 0.5512715651021589, 'val': 0.9670692734367201},\n",
       " {'train': 0.5704226292157994, 'val': 0.5723821946670228},\n",
       " {'train': 0.4943670801709165, 'val': 0.5520670835215182},\n",
       " {'train': 0.406910775068723, 'val': 0.38628757516012135},\n",
       " {'train': 0.5946378997370156, 'val': 0.693233331854394},\n",
       " {'train': 0.5538422217283312, 'val': 0.8387524940423599},\n",
       " {'train': 0.5129756636136815, 'val': 0.47453442577413446},\n",
       " {'train': 0.6535407473381898, 'val': 0.6111740742505485},\n",
       " {'train': 0.5916844033456929, 'val': 0.6728116200384897},\n",
       " {'train': 0.5931179222430558, 'val': 0.6246772825282134},\n",
       " {'train': 0.5484949065926874, 'val': 0.4282977877636452},\n",
       " {'train': 0.5292970746249208, 'val': 0.5647545084844513},\n",
       " {'train': 0.6123188359375664, 'val': 0.44318650636804713},\n",
       " {'train': 0.6064087030009728, 'val': 0.45929960628791167},\n",
       " {'train': 0.5407297484561965, 'val': 0.3919202876481251},\n",
       " {'train': 0.5793005348610855, 'val': 0.684214280664782},\n",
       " {'train': 0.546312441936273, 'val': 0.47001029581875586},\n",
       " {'train': 0.6347289432811782, 'val': 0.5960802897185822},\n",
       " {'train': 0.5989234648275361, 'val': 0.41376592199658674},\n",
       " {'train': 0.4096981698377113, 'val': 0.20921401493353853},\n",
       " {'train': 0.571761924570328, 'val': 0.4839793103373297},\n",
       " {'train': 0.6825612190324195, 'val': 0.6634253249932627},\n",
       " {'train': 0.46372244864885637, 'val': 0.3280453806613545}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/RealNVP/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\RealNVP_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with TTS GAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:51, 14.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.4033296433245175, 'val': 0.346253142740815},\n",
       " {'train': 0.44160962335612863, 'val': 0.6887987213064899},\n",
       " {'train': 0.15270834613223117, 'val': 0.15947363643142703},\n",
       " {'train': 0.1059298914431156, 'val': 0.08673123220468097},\n",
       " {'train': 0.2390187227632121, 'val': 0.23635228475615067},\n",
       " {'train': 0.7979688906555498, 'val': 0.8366779598930102},\n",
       " {'train': 0.5139242271435676, 'val': 0.6852156243025804},\n",
       " {'train': 0.7488439303803196, 'val': 0.5943480423695353},\n",
       " {'train': 0.2270093262426393, 'val': 0.19510159244237815},\n",
       " {'train': 0.22265766543676924, 'val': 0.2211849857563951},\n",
       " {'train': 1.1001916217256178, 'val': 1.0868589308255403},\n",
       " {'train': 0.9531175056031297, 'val': 0.7248833661241335},\n",
       " {'train': 0.7524001173862301, 'val': 0.7381950580076649},\n",
       " {'train': 0.5459293388254447, 'val': 0.3631415996951013},\n",
       " {'train': 0.8412013886954569, 'val': 0.5821116144416746},\n",
       " {'train': 3.7141621044628903, 'val': 3.7188648079103057},\n",
       " {'train': 0.7994655366449971, 'val': 0.8985482603995593},\n",
       " {'train': 0.3986146677453413, 'val': 0.3147644899017436},\n",
       " {'train': 0.531711876577568, 'val': 0.4674532869043445},\n",
       " {'train': 1.012060369037084, 'val': 0.6835439214402315},\n",
       " {'train': 7.075217077376028, 'val': 3.5988699157623563},\n",
       " {'train': 2.8469699684193555, 'val': 2.2902410571126914},\n",
       " {'train': 0.7233271471607332, 'val': 0.6787406180923709},\n",
       " {'train': 1.8035391767849247, 'val': 1.1472697150888118}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/TTS_GAN_standard/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\TTS_GAN_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing quality on real & synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_error as MAE, mean_absolute_percentage_error as MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsm_dataset_dir = Path(\"data/huge_stock_market_dataset/\")\n",
    "se_dataset_dir = Path(\"data/solar_energy/\")\n",
    "fp_dataset_dir = Path(\"data/fuel_prices/\")\n",
    "ap_dataset_dir = Path(\"data/air_passengers/\")\n",
    "results_dir = Path(\"results\")\n",
    "\n",
    "lags = 32\n",
    "horizon = 8\n",
    "stride = 1\n",
    "test_size = 0.3\n",
    "features = 1\n",
    "\n",
    "model_params = {\"silent\": True, \"random_seed\": 13, 'loss_function': 'MultiRMSE',  'eval_metric': 'MultiRMSE', \"iterations\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "1it [00:03,  3.52s/it]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "2it [00:06,  3.28s/it]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "3it [00:09,  3.21s/it]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "4it [00:12,  3.18s/it]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "5it [00:16,  3.18s/it]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "6it [00:19,  3.31s/it]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "7it [00:23,  3.44s/it]c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\data.py:70: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y = np.row_stack([y[i: i + horizon] for i in range(lags, len(y) - horizon + 1, stride)])\n",
      "8it [00:26,  3.31s/it]\n",
      "99it [03:20,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "start_point = 0\n",
    "start_ds = 2\n",
    "\n",
    "for ds_id, (dataset_path, dataset_name) in enumerate(((hsm_dataset_dir, \"hsm\"),\\\n",
    "     (se_dataset_dir, \"se\"), (fp_dataset_dir, \"fp\"),\\\n",
    "        (ap_dataset_dir, \"ap\"))):\n",
    "    if ds_id < start_ds: continue\n",
    "    if dataset_name == \"hsm\":\n",
    "        ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected100.csv\")\n",
    "    elif dataset_name == \"se\":\n",
    "        ts_iterator = get_solar_energy_dataset(dataset_path, max_results=10)\n",
    "    elif dataset_name == \"fp\":\n",
    "        ts_iterator = get_fuel_prices_dataset(dataset_path)\n",
    "    elif dataset_name == \"ap\":\n",
    "        ts_iterator = get_passengers_dataset(dataset_path, max_results=99)\n",
    "    for _ in range(start_point): next(ts_iterator)\n",
    "\n",
    "    # target_col = \"Close\" if dataset_name == \"hsm\" else \"Power(MW)\"\n",
    "    results = []\n",
    "    for time_series in tqdm(ts_iterator):\n",
    "        target_col = time_series.columns[0]\n",
    "        if dataset_name != \"hsm\": time_series += 1e-9\n",
    "        (X_train, y_train), _, (X_test, y_test), X_scaler, y_scaler = create_ts(time_series[[target_col]], time_series[target_col], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                data_preprocess=(\"log_returns\", \"normalize\"),\\\n",
    "                                                val_size=0, test_size=test_size)\n",
    "        X_train, X_test = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_test))\n",
    "        \n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        results.append(MAE(y_test, model.predict(X_test)))\n",
    "\n",
    "    pd.DataFrame(results, columns=[\"test\"]).to_csv(f\"results\\\\real_{dataset_name}_cbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing synthetic data from RealNVP on fp dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:54<00:00,  6.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing synthetic data from RealNVP on ap dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:56<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing synthetic data from FourierFlow on fp dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:51<00:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing synthetic data from FourierFlow on ap dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:39<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing synthetic data from TTS_GAN on fp dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:08<00:00,  8.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing synthetic data from TTS_GAN on ap dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:07<00:00,  8.56s/it]\n"
     ]
    }
   ],
   "source": [
    "start_synth_model = 1\n",
    "start_ds = 2\n",
    "ds_lens = {\"hsm\": 100, \"se\": 10, \"fp\": 8, \"ap\": 50}\n",
    "for synth_model_ind, synth_model in enumerate((\"QuantGAN\", \"RealNVP\", \"FourierFlow\", \"TTS_GAN\")):\n",
    "    if synth_model_ind < start_synth_model: continue\n",
    "    for ds_id, (dataset_path, dataset_name) in enumerate(((Path(\"data/huge_stock_market_dataset/synthetic/\"), \"hsm\"),\\\n",
    "     (Path(\"data/solar_energy/synthetic/\"), \"se\"), (Path(\"data/fuel_prices/synthetic/\"), \"fp\"),\\\n",
    "        (Path(\"data/air_passengers/synthetic/\"), \"ap\"))):\n",
    "        if ds_id < start_ds: continue\n",
    "        synth_path = dataset_path / synth_model\n",
    "        results = []\n",
    "        print(f\"Testing synthetic data from {synth_model} on {dataset_name} dataset\")\n",
    "        for ts_index in tqdm(range(ds_lens[dataset_name])):\n",
    "            synth_time_series = np.load(synth_path / f\"selected{ts_index}.npy\")\n",
    "            if len(synth_time_series) > 0:\n",
    "                results.append(0)\n",
    "                num_synth_samples = min(10, synth_time_series.shape[0]) if synth_model in (\"QuantGAN\", \"TTS_GAN\") else 2\n",
    "                for i in range(num_synth_samples):\n",
    "                    (X_train, y_train), _, (X_test, y_test), X_scaler, y_scaler = create_ts(synth_time_series[i].reshape(- 1, 1), synth_time_series[i].flatten(), lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                        data_preprocess=(\"normalize\",), val_size=0, test_size=test_size)\n",
    "                    X_train, X_test = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_test))\n",
    "                    \n",
    "                    model = CatBoostRegressor(**model_params)\n",
    "                    model.fit(X_train, y_train)\n",
    "                \n",
    "                    results[- 1] += MAE(y_test, model.predict(X_test))\n",
    "                results[- 1] /= num_synth_samples\n",
    "            else:\n",
    "                results.append(1)\n",
    "        pd.DataFrame(results, columns=[\"test\"]).to_csv(results_dir / f\"synth_{synth_model}_{dataset_name}_cbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
