{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils.data import get_hsm_dataset, get_solar_energy_dataset, get_fuel_prices_dataset, get_passengers_dataset, split_data\n",
    "from utils.metrics import MAPE, WAPE, MAE\n",
    "from utils.dl import QuantGAN_Discriminator, QuantGAN_Generator\n",
    "from utils.QuantGAN_gaussianize import Gaussianize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsm_dataset_path = Path(\"data/huge_stock_market_dataset/\")\n",
    "solar_energy_dataset_path = Path(\"data/solar_energy/\")\n",
    "fuel_prices_dataset_path = Path(\"data/fuel_prices/\")\n",
    "passengers_dataset_path = Path(\"data/air_passengers/\")\n",
    "models_dir = Path(\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batches_to_gen = 1\n",
    "\n",
    "num_epochs = 10\n",
    "nz = 3\n",
    "batch_size = 80\n",
    "seq_len = 127\n",
    "clip = 0.01\n",
    "lr = 0.0002\n",
    "receptive_field_size = 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader32(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, length):\n",
    "        assert len(data) >= length\n",
    "        self.data = data\n",
    "        self.length = length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx:idx+self.length]).reshape(- 1, self.length).to(torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return max(len(self.data)-self.length, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_routine(time_series, ts_index, synthetic_path):\n",
    "    global val_size, test_size, batches_to_gen, num_epochs, nz, batch_size, seq_len, clip, lr, receptive_field_size\n",
    "    \n",
    "    # preprocessing steps according to the QuanGAN paper\n",
    "    df = time_series\n",
    "    # returns = df.shift(1) / df - 1\n",
    "    # log_returns = np.log(df / df.shift(1))[1:].to_numpy().reshape(- 1, 1)\n",
    "    log_returns = df.values.reshape(- 1, 1)\n",
    "    standardScaler1 = StandardScaler()\n",
    "    standardScaler2 = StandardScaler()\n",
    "    gaussianize = Gaussianize()\n",
    "    log_returns_preprocessed = standardScaler2.fit_transform(gaussianize.fit_transform(standardScaler1.fit_transform(log_returns)))\n",
    "    data_size = log_returns.shape[0]\n",
    "\n",
    "    # defining models and optimizers\n",
    "    generator = QuantGAN_Generator().to(device)\n",
    "    discriminator = QuantGAN_Discriminator(seq_len).to(device)\n",
    "    disc_optimizer = torch.optim.RMSprop(discriminator.parameters(), lr=lr)\n",
    "    gen_optimizer = torch.optim.RMSprop(generator.parameters(), lr=lr)\n",
    "\n",
    "    # data preparing\n",
    "    dataset = Loader32(log_returns_preprocessed, receptive_field_size)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    t = tqdm(range(num_epochs))\n",
    "    for epoch in t:\n",
    "        for idx, data in enumerate(dataloader, 0):\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            real = data.to(device)\n",
    "            batch_size, seq_len = real.size(0), real.size(2)\n",
    "            noise = torch.randn(batch_size, nz, seq_len, device=device)\n",
    "            fake = generator(noise).detach()\n",
    "            disc_loss = - torch.mean(discriminator(real)) + torch.mean(discriminator(fake))\n",
    "            disc_loss.backward()\n",
    "            disc_optimizer.step()\n",
    "\n",
    "            for dp in discriminator.parameters():\n",
    "                dp.data.clamp_(-clip, clip)\n",
    "    \n",
    "            if idx % 5 == 0:\n",
    "                generator.zero_grad()\n",
    "                gen_loss = - torch.mean(discriminator(generator(noise)))\n",
    "                gen_loss.backward()\n",
    "                gen_optimizer.step()\n",
    "        t.set_description('Discriminator Loss: %.8f Generator Loss: %.8f' % (disc_loss.item(), gen_loss.item()))\n",
    "    # saving model\n",
    "    torch.save(generator, models_dir /  f'QuantGAN_generator_selected{ts_index}.pth')\n",
    "\n",
    "    # generation synthetic time series\n",
    "    generator.eval()\n",
    "    ys = []\n",
    "    for _ in range(batches_to_gen):\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(80, 3, 127).to(device)\n",
    "            y = generator(noise).cpu().detach().squeeze()\n",
    "\n",
    "        y = (y - y.mean(axis=0)) / y.std(axis=0)\n",
    "        y = standardScaler2.inverse_transform(y)\n",
    "        y = np.array([gaussianize.inverse_transform(np.expand_dims(x, 1)) for x in y]).squeeze()\n",
    "        y = standardScaler1.inverse_transform(y)\n",
    "\n",
    "        # some basic filtering to redue the tendency of GAN to produce extreme returns\n",
    "        # y = y[(y.max(axis=1) <= 2 * log_returns.max()) & (y.min(axis=1) >= 2 * log_returns.min())]\n",
    "        # y -= y.mean()\n",
    "        ys.append(y)\n",
    "\n",
    "    np.save(synthetic_path / f\"selected{ts_index}.npy\", np.row_stack(ys))\n",
    "\n",
    "    del discriminator, generator, disc_loss, gen_loss, dataloader, dataset, y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_iterator = get_hsm_dataset(hsm_dataset_path, selected_files=hsm_dataset_path / \"selected100.csv\")\n",
    "synthetic_path = hsm_dataset_path / \"synthetic/QuantGAN/\"\n",
    "start_point = 100\n",
    "for _ in range(start_point): next(ts_iterator)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator, start_point):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    model_routine(time_series, ts_index, synthetic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00000340 Generator Loss: -0.49755979: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00000247 Generator Loss: -0.49791011: 100%|██████████| 4/4 [00:03<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\QuantGAN_gaussianize.py:171: UserWarning: Warning: No convergence after 100 iterations. Increase max_iter.\n",
      "  warnings.warn(\"Warning: No convergence after %d iterations. Increase max_iter.\" % max_iter)\n",
      "Discriminator Loss: -0.00002259 Generator Loss: -0.49741653: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00003412 Generator Loss: -0.49763224: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00001574 Generator Loss: -0.50241703: 100%|██████████| 4/4 [00:10<00:00,  2.55s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00008953 Generator Loss: -0.50079763: 100%|██████████| 4/4 [00:55<00:00, 13.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00010329 Generator Loss: -0.49743944: 100%|██████████| 4/4 [00:44<00:00, 11.22s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00026551 Generator Loss: -0.49971384: 100%|██████████| 4/4 [00:45<00:00, 11.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00007766 Generator Loss: -0.50215000: 100%|██████████| 4/4 [00:45<00:00, 11.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00013888 Generator Loss: -0.49666637: 100%|██████████| 4/4 [00:46<00:00, 11.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\QuantGAN_gaussianize.py:171: UserWarning: Warning: No convergence after 100 iterations. Increase max_iter.\n",
      "  warnings.warn(\"Warning: No convergence after %d iterations. Increase max_iter.\" % max_iter)\n",
      "Discriminator Loss: -0.00019023 Generator Loss: -0.49651274: 100%|██████████| 4/4 [00:47<00:00, 11.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00009704 Generator Loss: -0.49957937: 100%|██████████| 4/4 [00:45<00:00, 11.44s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00009269 Generator Loss: -0.50041807: 100%|██████████| 4/4 [00:45<00:00, 11.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00000060 Generator Loss: -0.49774498: 100%|██████████| 4/4 [00:45<00:00, 11.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00048095 Generator Loss: -0.50217146: 100%|██████████| 4/4 [00:48<00:00, 12.03s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\QuantGAN_gaussianize.py:171: UserWarning: Warning: No convergence after 100 iterations. Increase max_iter.\n",
      "  warnings.warn(\"Warning: No convergence after %d iterations. Increase max_iter.\" % max_iter)\n",
      "Discriminator Loss: 0.00029090 Generator Loss: -0.49911612: 100%|██████████| 4/4 [00:55<00:00, 13.79s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00006634 Generator Loss: -0.49806985: 100%|██████████| 4/4 [00:48<00:00, 12.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\QuantGAN_gaussianize.py:171: UserWarning: Warning: No convergence after 100 iterations. Increase max_iter.\n",
      "  warnings.warn(\"Warning: No convergence after %d iterations. Increase max_iter.\" % max_iter)\n",
      "Discriminator Loss: 0.00052065 Generator Loss: -0.50203645: 100%|██████████| 4/4 [00:49<00:00, 12.40s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00005841 Generator Loss: -0.49957877: 100%|██████████| 4/4 [00:47<00:00, 11.94s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00009289 Generator Loss: -0.49923712: 100%|██████████| 4/4 [00:46<00:00, 11.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00031963 Generator Loss: -0.49999103: 100%|██████████| 4/4 [00:46<00:00, 11.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00095630 Generator Loss: -0.49877414: 100%|██████████| 4/4 [00:46<00:00, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00109467 Generator Loss: -0.49757618: 100%|██████████| 4/4 [00:45<00:00, 11.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00135541 Generator Loss: -0.49720734: 100%|██████████| 4/4 [00:46<00:00, 11.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00045007 Generator Loss: -0.49698269: 100%|██████████| 4/4 [00:46<00:00, 11.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00017413 Generator Loss: -0.49993762: 100%|██████████| 4/4 [00:45<00:00, 11.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00021067 Generator Loss: -0.49998456: 100%|██████████| 4/4 [00:46<00:00, 11.57s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00055170 Generator Loss: -0.50052398: 100%|██████████| 4/4 [00:46<00:00, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\QuantGAN_gaussianize.py:171: UserWarning: Warning: No convergence after 100 iterations. Increase max_iter.\n",
      "  warnings.warn(\"Warning: No convergence after %d iterations. Increase max_iter.\" % max_iter)\n",
      "Discriminator Loss: 0.00018197 Generator Loss: -0.49560308: 100%|██████████| 4/4 [00:46<00:00, 11.54s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00001577 Generator Loss: -0.49671698: 100%|██████████| 4/4 [00:46<00:00, 11.66s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00014225 Generator Loss: -0.50016987: 100%|██████████| 4/4 [00:46<00:00, 11.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00022626 Generator Loss: -0.50237024: 100%|██████████| 4/4 [00:46<00:00, 11.51s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00004840 Generator Loss: -0.49929780: 100%|██████████| 4/4 [00:46<00:00, 11.51s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00019330 Generator Loss: -0.50210810: 100%|██████████| 4/4 [00:46<00:00, 11.57s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00030315 Generator Loss: -0.50123662: 100%|██████████| 4/4 [00:46<00:00, 11.58s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00005788 Generator Loss: -0.49786600: 100%|██████████| 4/4 [00:45<00:00, 11.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00008249 Generator Loss: -0.50003004: 100%|██████████| 4/4 [00:46<00:00, 11.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00020587 Generator Loss: -0.50175810: 100%|██████████| 4/4 [00:46<00:00, 11.52s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00029317 Generator Loss: -0.49961543: 100%|██████████| 4/4 [00:46<00:00, 11.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00005576 Generator Loss: -0.49910176: 100%|██████████| 4/4 [00:46<00:00, 11.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00018802 Generator Loss: -0.49747986: 100%|██████████| 4/4 [00:47<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00011683 Generator Loss: -0.50045413: 100%|██████████| 4/4 [00:46<00:00, 11.65s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00047982 Generator Loss: -0.50229728: 100%|██████████| 4/4 [00:48<00:00, 12.18s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00025398 Generator Loss: -0.50036353: 100%|██████████| 4/4 [00:48<00:00, 12.07s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\QuantGAN_gaussianize.py:171: UserWarning: Warning: No convergence after 100 iterations. Increase max_iter.\n",
      "  warnings.warn(\"Warning: No convergence after %d iterations. Increase max_iter.\" % max_iter)\n",
      "Discriminator Loss: 0.00045741 Generator Loss: -0.50209105: 100%|██████████| 4/4 [00:48<00:00, 12.11s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00024328 Generator Loss: -0.49937677: 100%|██████████| 4/4 [00:47<00:00, 11.98s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\utils\\QuantGAN_gaussianize.py:171: UserWarning: Warning: No convergence after 100 iterations. Increase max_iter.\n",
      "  warnings.warn(\"Warning: No convergence after %d iterations. Increase max_iter.\" % max_iter)\n",
      "Discriminator Loss: 0.00001580 Generator Loss: -0.49796569: 100%|██████████| 4/4 [00:50<00:00, 12.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00004968 Generator Loss: -0.49977753: 100%|██████████| 4/4 [00:48<00:00, 12.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 0.00009620 Generator Loss: -0.50028276: 100%|██████████| 4/4 [00:52<00:00, 13.15s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -0.00003392 Generator Loss: -0.49791306: 100%|██████████| 4/4 [00:48<00:00, 12.08s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "ts_iterator = get_solar_energy_dataset(solar_energy_dataset_path)\n",
    "synthetic_path = solar_energy_dataset_path / \"synthetic/QuantGAN/\"\n",
    "start_point = 0\n",
    "for _ in range(start_point): next(ts_iterator)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator, start_point):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    model_routine(time_series, ts_index, synthetic_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45 sec 1 ts 3k\n",
    "\n",
    "6 min 1 ts 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "ts_iterator = get_fuel_prices_dataset(fuel_prices_dataset_path)\n",
    "synthetic_path = fuel_prices_dataset_path / \"synthetic/QuantGAN/\"\n",
    "start_point = 8\n",
    "for _ in range(start_point): next(ts_iterator)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator, start_point):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    model_routine(time_series, ts_index, synthetic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "ts_iterator = get_passengers_dataset(passengers_dataset_path, max_results=99)\n",
    "synthetic_path = passengers_dataset_path / \"synthetic/QuantGAN/\"\n",
    "start_point = 99\n",
    "for _ in range(start_point): next(ts_iterator)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator, start_point):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    model_routine(time_series, ts_index, synthetic_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import kl_div\n",
    "\n",
    "from utils.data import get_hsm_dataset, get_solar_energy_dataset, get_fuel_prices_dataset, get_passengers_dataset, split_data, log_returns\n",
    "from utils.synth_eval import eval_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"results\")\n",
    "seq_len = 127\n",
    "hsm_dataset_path, solar_energy_dataset_path, fuel_prices_dataset_path, passengers_dataset_path = [Path(x) for x in (hsm_dataset_path, solar_energy_dataset_path, fuel_prices_dataset_path, passengers_dataset_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing hsm dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:14,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing se dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "1it [00:00,  1.09it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "2it [00:01,  1.11it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "3it [00:02,  1.12it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "4it [00:03,  1.11it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "5it [00:04,  1.11it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "6it [00:05,  1.10it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "7it [00:06,  1.05it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "8it [00:07,  1.08it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "9it [00:08,  1.09it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "10it [00:09,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fp dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ap dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:12,  2.79s/it]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "4it [00:12,  1.82s/it]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "6it [00:12,  1.05it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "19it [00:17,  2.95it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "28it [00:20,  3.00it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "31it [00:21,  2.98it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "43it [00:25,  3.03it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "47it [00:26,  3.01it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "55it [00:29,  2.86it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "60it [00:31,  2.35it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "62it [00:32,  2.33it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "65it [00:33,  2.53it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "67it [00:34,  2.71it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "69it [00:34,  2.83it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "71it [00:35,  2.92it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "73it [00:36,  2.78it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "74it [00:36,  2.77it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "78it [00:38,  2.64it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "82it [00:39,  2.74it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "84it [00:40,  2.83it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "85it [00:40,  2.89it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "96it [00:44,  2.86it/s]c:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "99it [00:45,  2.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'hsm': {'kl_div': inf, 'kstest_pval': 3.703076513218439e-31},\n",
       "             'se': {'kl_div': nan, 'kstest_pval': 1.3039956366633642e-20},\n",
       "             'fp': {'kl_div': inf, 'kstest_pval': 1.3813869469290808e-75},\n",
       "             'ap': {'kl_div': nan, 'kstest_pval': 8.354717247922456e-35}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sim((\"hsm\", \"se\", \"fp\", \"ap\"), (hsm_dataset_path, solar_energy_dataset_path, fuel_prices_dataset_path, passengers_dataset_path),\n",
    "     \"QuantGAN\", save=True, results_dir=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
