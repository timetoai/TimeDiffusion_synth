{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322ef4d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T16:07:52.183107Z",
     "iopub.status.busy": "2022-11-21T16:07:52.182112Z",
     "iopub.status.idle": "2022-11-21T16:07:57.243245Z",
     "shell.execute_reply": "2022-11-21T16:07:57.241811Z"
    },
    "papermill": {
     "duration": 5.067812,
     "end_time": "2022-11-21T16:07:57.246221",
     "exception": false,
     "start_time": "2022-11-21T16:07:52.178409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.data import get_dataset_iterator\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils.dl import QuantGAN_TemporalBlock\n",
    "\n",
    "data_path = Path(\"data\")\n",
    "models_dir = Path(\"models\")\n",
    "\n",
    "hsm_dataset_path = data_path / \"huge_stock_market_dataset\"\n",
    "solar_energy_dataset_path = data_path / \"solar_energy\"\n",
    "fuel_prices_dataset_path = data_path / \"fuel_prices\"\n",
    "passengers_dataset_path = data_path / \"air_passengers\"\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4e4afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T16:07:57.290905Z",
     "iopub.status.busy": "2022-11-21T16:07:57.290379Z",
     "iopub.status.idle": "2022-11-21T18:49:10.029398Z",
     "shell.execute_reply": "2022-11-21T18:49:10.028343Z"
    },
    "papermill": {
     "duration": 9672.746812,
     "end_time": "2022-11-21T18:49:10.032404",
     "exception": false,
     "start_time": "2022-11-21T16:07:57.285592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [04:31, 135.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# 3rd version (5, 256, 32) + high freq preprocessing + new gen\n",
    "def is_high_freq(time_series, threshold=0.5, rolling_parts=200):\n",
    "    orig_std = time_series.std().values[0]\n",
    "    ma_ts = time_series.rolling(len(time_series) // rolling_parts).mean()\n",
    "    ma_std = ma_ts.std().values[0]\n",
    "    return abs(ma_std - orig_std) / orig_std > threshold\n",
    "\n",
    "def ma(time_series, rolling_parts=200, window=None):\n",
    "    if window is None:\n",
    "        window = max(len(time_series) // rolling_parts, 2)\n",
    "    ts1 = time_series.rolling(window, closed=\"left\").mean()\n",
    "    ts2 = time_series[:: - 1].rolling(window).mean()[:: - 1]\n",
    "    ts1[ts1.isna()] = ts2[ts1.isna()]\n",
    "    ts2[ts2.isna()] = ts1[ts2.isna()]\n",
    "    ats = (ts1 + ts2) / 2\n",
    "    return ats\n",
    "\n",
    "\n",
    "class TimeDIffusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tcn = nn.ModuleList([QuantGAN_TemporalBlock(1, 128, kernel_size=1, stride=1, dilation=1, padding=0, dropout=0.25),\n",
    "                                 *[QuantGAN_TemporalBlock(128, 128, kernel_size=2, stride=1, dilation=i, padding=i, dropout=0.0)\n",
    "                                        for i in [2 ** i for i in range(14)]]])\n",
    "        self.last = nn.Conv1d(128, 1, kernel_size=1, stride=1, dilation=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_layers = []\n",
    "        for layer in self.tcn:\n",
    "            skip, x = layer(x)\n",
    "            skip_layers.append(skip)\n",
    "        x = self.last(x + sum(skip_layers))\n",
    "        return x\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "steps_per_epoch = 32\n",
    "samples_to_gen = 20\n",
    "steps_to_gen = set(range(3, 3 + samples_to_gen))\n",
    "max_gen_step = max(steps_to_gen) + 1\n",
    "batch_size = 32\n",
    "\n",
    "for dataset_ind, (dataset_name, dataset_path) in enumerate(\n",
    "    (\n",
    "    # (\"hsm\", hsm_dataset_path),\n",
    "    # (\"se\", solar_energy_dataset_path),\n",
    "    (\"fp\", fuel_prices_dataset_path),\n",
    "    # (\"ap\", passengers_dataset_path)\n",
    ")):\n",
    "    ts_iterator = get_dataset_iterator(dataset_name, dataset_path)\n",
    "    out_dataset_dir = dataset_path / \"synthetic/TimeDiffusion\"\n",
    "    if not out_dataset_dir.exists():\n",
    "        out_dataset_dir.mkdir()\n",
    "    \n",
    "    start_point = 6\n",
    "    for _ in range(start_point): next(ts_iterator)\n",
    "    ts_index = - 1 + start_point\n",
    "    for time_series in tqdm(ts_iterator):\n",
    "        ts_index += 1\n",
    "        \n",
    "        # high freq check\n",
    "        if is_high_freq(time_series):\n",
    "            time_series = ma(time_series)\n",
    "        \n",
    "        train = time_series.values.flatten()\n",
    "        tmean = train.mean()\n",
    "        tstd = train.std()\n",
    "        train = (train - tmean) / tstd\n",
    "        train_tensor = torch.from_numpy(train).float().to(device)\n",
    "\n",
    "        torch.random.manual_seed(0)\n",
    "        model = TimeDIffusion().to(device)\n",
    "        optim = torch.optim.AdamW(model.parameters(), lr=4e-4)\n",
    "        losses = []\n",
    "#         kl_divs = []\n",
    "#         val_noise = torch.rand(20, 1, len(train)).to(device)\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "#         for epoch in tqdm(range(1, epochs + 1)):\n",
    "            model.train()\n",
    "            X = train_tensor.repeat(batch_size, 1).unsqueeze(1)\n",
    "            noise = torch.row_stack([torch.rand(1, *X.shape[1:]) for _ in range(X.shape[0])]).to(device)\n",
    "            noise_level = torch.rand(X.shape).to(device)\n",
    "            noise *= noise_level\n",
    "\n",
    "            for step in range(steps_per_epoch):\n",
    "                optim.zero_grad()\n",
    "                y_hat = model(X + noise)\n",
    "                loss = (y_hat - noise).abs().mean()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                with torch.no_grad():\n",
    "                    noise -= y_hat\n",
    "                losses.append(loss.item())\n",
    "    \n",
    "        model.eval()\n",
    "        result = []\n",
    "        with torch.no_grad():\n",
    "            generated = torch.rand(samples_to_gen // len(steps_to_gen), 1, len(train)).to(device)\n",
    "            for step in range(1, steps_per_epoch + 1):\n",
    "                pred_noise = model(generated)\n",
    "                generated -= pred_noise\n",
    "                if step in steps_to_gen:\n",
    "                    result.append(generated.detach().cpu().numpy().squeeze() * tstd + tmean)\n",
    "        result = np.row_stack(result)\n",
    "        np.save(out_dataset_dir / f\"selected{ts_index}.npy\", result)\n",
    "        torch.save(model.state_dict(), models_dir / f\"TimeDiffusion_{dataset_name}_{ts_index}.pt\")\n",
    "        del model, optim, generated\n",
    "             \n",
    "#             steps = steps_per_epoch * 2\n",
    "#             with torch.no_grad():\n",
    "#                 model.eval()\n",
    "#                 generated = val_noise\n",
    "#                 for step in range(1, steps + 1):\n",
    "#                     pred_noise = model(generated)\n",
    "#                     generated -= pred_noise\n",
    "#                 generated = generated.detach().cpu().numpy().squeeze()\n",
    "#             kl_divs.append(np.mean([np.mean([x for x in kl_div(generated[i], train) if not np.isnan(x) and not np.isinf(x)])\n",
    "#                                 for i in range(len(generated))]))\n",
    " \n",
    "#         plt.plot(losses)\n",
    "#         plt.show()\n",
    "#         plt.plot(kl_divs)\n",
    "#         print(kl_divs)\n",
    "        \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab172bc",
   "metadata": {},
   "source": [
    "2:19 1 ts ~1k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0586",
   "metadata": {
    "papermill": {
     "duration": 0.003351,
     "end_time": "2022-11-21T18:49:10.039617",
     "exception": false,
     "start_time": "2022-11-21T18:49:10.036266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "noise thresholds (steps): 1.4 (25/256), 0.9 (41/256), 0.68 (15/256), 0.04 (98/256), 0.55 (65/256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06484c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T18:49:10.048086Z",
     "iopub.status.busy": "2022-11-21T18:49:10.047771Z",
     "iopub.status.idle": "2022-11-21T18:49:10.052898Z",
     "shell.execute_reply": "2022-11-21T18:49:10.051868Z"
    },
    "papermill": {
     "duration": 0.011853,
     "end_time": "2022-11-21T18:49:10.055022",
     "exception": false,
     "start_time": "2022-11-21T18:49:10.043169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# steps = steps_per_epoch // 2\n",
    "# plot_rate = steps // 5\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     noise = torch.rand(1, 1, len(train)).to(device)\n",
    "#     generated = noise\n",
    "#     kl_divs = []\n",
    "#     pred_noises = []\n",
    "#     for step in range(1, steps + 1):\n",
    "#         pred_noise = model(generated)\n",
    "#         generated -= pred_noise\n",
    "        \n",
    "#         pred_noises.append(pred_noise.sum().item())\n",
    "#         kl_divs.append(kl_div(generated.detach().cpu().squeeze().numpy(), train).mean())\n",
    "        \n",
    "#         if step % plot_rate == 0:\n",
    "\n",
    "#             result = generated.detach().cpu().squeeze().numpy()\n",
    "#             plt.plot(train)\n",
    "#             plt.plot(result)\n",
    "#             plt.legend([\"ground truth\", \"synthetic\"])\n",
    "#             plt.title(f\"Step #{step} pred_noise: {pred_noises[- 1]:0.4f} kl_div: {kl_divs[- 1]: 0.4f}\")\n",
    "#             plt.show()\n",
    "    \n",
    "#     plt.plot(range(len(kl_divs)), kl_divs)\n",
    "#     ind = np.argmin(kl_divs)\n",
    "#     plt.title(\"kl_div \" + str(ind))\n",
    "#     plt.show()\n",
    "#     plt.plot(range(len(pred_noises)), pred_noises)\n",
    "#     plt.title(\"pred noises\")\n",
    "#     plt.show()\n",
    "#     print(kl_divs[ind], pred_noises[ind])\n",
    "# # plt.plot(noise.cpu().numpy().squeeze())\n",
    "# # plt.plot(pred_noise.cpu().numpy().squeeze())\n",
    "# # plt.legend([\"noise\", \"pred_noise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ed094",
   "metadata": {
    "papermill": {
     "duration": 0.00338,
     "end_time": "2022-11-21T18:49:10.061929",
     "exception": false,
     "start_time": "2022-11-21T18:49:10.058549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9690.933553,
   "end_time": "2022-11-21T18:49:12.391501",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-21T16:07:41.457948",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
