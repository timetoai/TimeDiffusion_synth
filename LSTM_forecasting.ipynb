{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "from utils.metrics import MAPE, WAPE, MAE\n",
    "from utils.dl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "lags = 32\n",
    "horizon = 8\n",
    "stride = 1\n",
    "batch_size = 256\n",
    "val_size = 0.15\n",
    "test_size = 0.0\n",
    "drop_last = False\n",
    "features = 1\n",
    "keep_hs = False  # stride == lags\n",
    "epochs = 200\n",
    "verbose = False\n",
    "\n",
    "model_params = {'input_size': features, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.1, 'output_size': horizon, 'seq_len': lags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:09,  9.65s/it]Global seed set to 0\n",
      "2it [00:23, 11.92s/it]Global seed set to 0\n",
      "3it [00:36, 12.53s/it]Global seed set to 0\n",
      "4it [00:48, 12.25s/it]Global seed set to 0\n",
      "5it [00:57, 11.01s/it]Global seed set to 0\n",
      "6it [01:23, 16.30s/it]Global seed set to 0\n",
      "7it [01:43, 17.62s/it]Global seed set to 0\n",
      "8it [02:06, 19.08s/it]Global seed set to 0\n",
      "9it [02:34, 21.97s/it]Global seed set to 0\n",
      "10it [02:57, 22.24s/it]Global seed set to 0\n",
      "11it [03:39, 28.33s/it]Global seed set to 0\n",
      "12it [04:22, 32.90s/it]Global seed set to 0\n",
      "13it [05:05, 35.73s/it]Global seed set to 0\n",
      "14it [05:42, 36.13s/it]Global seed set to 0\n",
      "15it [06:29, 39.44s/it]Global seed set to 0\n",
      "16it [07:18, 42.35s/it]Global seed set to 0\n",
      "17it [08:10, 45.33s/it]Global seed set to 0\n",
      "18it [09:02, 47.32s/it]Global seed set to 0\n",
      "19it [09:54, 48.75s/it]Global seed set to 0\n",
      "20it [10:47, 49.84s/it]Global seed set to 0\n",
      "21it [13:52, 90.65s/it]Global seed set to 0\n",
      "22it [17:18, 125.18s/it]Global seed set to 0\n",
      "23it [19:08, 120.52s/it]Global seed set to 0\n",
      "24it [20:38, 51.60s/it] \n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "results = []\n",
    "for time_series in tqdm(ts_iterator):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "    \n",
    "    model = RNNModel(seed=0, device=device)\n",
    "    model.set_model(SimpleLSTM, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    model.train(train_dl, epochs=epochs, print_info=verbose, keep_hs=keep_hs, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.09587069973349571, 'val': 0.09166862070560455},\n",
       " {'train': 0.03804870073994001, 'val': 0.052777111530303955},\n",
       " {'train': 0.007281795144081116, 'val': 0.005239419639110565},\n",
       " {'train': 0.009841733146458864, 'val': 0.010587431490421295},\n",
       " {'train': 0.016299376729875803, 'val': 0.012811913155019283},\n",
       " {'train': 0.0273998969544967, 'val': 0.027212876826524734},\n",
       " {'train': 0.0268426064401865, 'val': 0.03662586584687233},\n",
       " {'train': 0.01703375708311796, 'val': 0.015111961401998997},\n",
       " {'train': 0.008660931993896762, 'val': 0.006156163290143013},\n",
       " {'train': 0.00804837578907609, 'val': 0.00693837646394968},\n",
       " {'train': 0.052466646250751287, 'val': 0.0384663101285696},\n",
       " {'train': 0.03620564006268978, 'val': 0.020883575081825256},\n",
       " {'train': 0.03437461662623617, 'val': 0.0320797311142087},\n",
       " {'train': 0.011673742556013167, 'val': 0.006538719404488802},\n",
       " {'train': 0.018509079050272704, 'val': 0.010300817899405956},\n",
       " {'train': 0.0391908086836338, 'val': 0.027567469514906406},\n",
       " {'train': 0.028186453167687763, 'val': 0.02164100483059883},\n",
       " {'train': 0.006612683307718147, 'val': 0.006440143333747983},\n",
       " {'train': 0.018086512149734932, 'val': 0.01690222369506955},\n",
       " {'train': 0.00916615187783133, 'val': 0.005506517365574837},\n",
       " {'train': 0.014759757862377324, 'val': 0.00724196620285511},\n",
       " {'train': 0.008729508088435978, 'val': 0.006687861285172403},\n",
       " {'train': 0.023221570593507393, 'val': 0.028383863158524036},\n",
       " {'train': 0.01666795356983417, 'val': 0.008739217068068683}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\pure_LSTM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with QuantGAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_path = f\"{dataset_path}synthetic/QuantGAN/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDataLoader:\n",
    "    def __init__(self, *dls):\n",
    "        self.dls = dls\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(map(len, self.dls))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for dl in self.dls:\n",
    "            for v in dl:\n",
    "                yield v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:37, 37.08s/it]Global seed set to 0\n",
      "2it [01:12, 36.04s/it]Global seed set to 0\n",
      "3it [01:45, 34.79s/it]Global seed set to 0\n",
      "4it [02:19, 34.33s/it]Global seed set to 0\n",
      "5it [02:52, 33.77s/it]Global seed set to 0\n",
      "6it [03:25, 33.58s/it]Global seed set to 0\n",
      "7it [03:59, 33.85s/it]Global seed set to 0\n",
      "8it [04:35, 34.52s/it]Global seed set to 0\n",
      "9it [05:12, 35.09s/it]Global seed set to 0\n",
      "10it [05:48, 35.37s/it]Global seed set to 0\n",
      "11it [06:17, 33.50s/it]Global seed set to 0\n",
      "12it [06:57, 35.42s/it]Global seed set to 0\n",
      "13it [07:36, 36.66s/it]Global seed set to 0\n",
      "14it [08:13, 36.72s/it]Global seed set to 0\n",
      "15it [08:50, 36.75s/it]Global seed set to 0\n",
      "16it [09:26, 36.73s/it]Global seed set to 0\n",
      "17it [10:02, 36.50s/it]Global seed set to 0\n",
      "18it [10:40, 36.79s/it]Global seed set to 0\n",
      "19it [11:16, 36.63s/it]Global seed set to 0\n",
      "20it [11:52, 36.46s/it]Global seed set to 0\n",
      "21it [12:30, 36.87s/it]Global seed set to 0\n",
      "22it [13:08, 37.28s/it]Global seed set to 0\n",
      "23it [13:46, 37.47s/it]Global seed set to 0\n",
      "24it [14:25, 36.06s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "epochs = 2\n",
    "\n",
    "results = []\n",
    "for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "\n",
    "    synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "    synth_dls = []\n",
    "    for i in range(synth_time_series.shape[0]):\n",
    "        synth_dl, *_ = create_ts_dl(synth_time_series[i].reshape(127, 1), synth_time_series[i], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=None,\\\n",
    "                                            val_size=0, test_size=0, drop_last=drop_last)\n",
    "        synth_dls.append(synth_dl)\n",
    "    \n",
    "    model = RNNModel(seed=0, device=device)\n",
    "    model.set_model(SimpleLSTM, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    # cdl = CombinedDataLoader(train_dl, *synth_dls)\n",
    "    # only synth data\n",
    "    cdl = CombinedDataLoader(*synth_dls)\n",
    "    model.train(cdl, epochs=epochs, print_info=verbose, keep_hs=keep_hs, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.10761301219463348, 'val': 0.08768519759178162},\n",
       " {'train': 0.03998527179161707, 'val': 0.05282701551914215},\n",
       " {'train': 0.007818675444771847, 'val': 0.005705437157303095},\n",
       " {'train': 0.010074544697999954, 'val': 0.01072484441101551},\n",
       " {'train': 0.01676370482891798, 'val': 0.012739374302327633},\n",
       " {'train': 0.029049171445270378, 'val': 0.027288392186164856},\n",
       " {'train': 0.029441210627555846, 'val': 0.03475208207964897},\n",
       " {'train': 0.01741277687251568, 'val': 0.014956658706068993},\n",
       " {'train': 0.008807544053221742, 'val': 0.006362587679177523},\n",
       " {'train': 0.008097720332443714, 'val': 0.006888795644044876},\n",
       " {'train': 0.0534266730149587, 'val': 0.03936200402677059},\n",
       " {'train': 0.038627251154846616, 'val': 0.020633424632251263},\n",
       " {'train': 0.035616915259096354, 'val': 0.03144158702343702},\n",
       " {'train': 0.01203392876777798, 'val': 0.006497248541563749},\n",
       " {'train': 0.018806928768754005, 'val': 0.010355071164667606},\n",
       " {'train': 0.043070480972528455, 'val': 0.026674081571400166},\n",
       " {'train': 0.030886958945881237, 'val': 0.021625149995088577},\n",
       " {'train': 0.0066903841004452924, 'val': 0.006430623820051551},\n",
       " {'train': 0.01833771363916722, 'val': 0.016719270031899214},\n",
       " {'train': 0.009203642395071009, 'val': 0.00546214752830565},\n",
       " {'train': 0.015535655480466391, 'val': 0.00775382195466331},\n",
       " {'train': 0.009252514864783734, 'val': 0.006794267799705267},\n",
       " {'train': 0.023389302720518215, 'val': 0.028370188549160957},\n",
       " {'train': 0.018314090140752103, 'val': 0.00863989896606654}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\QuantGAN_synth_LSTM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with FourierFlow synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_path = f\"{dataset_path}synthetic/FourierFlow/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:45, 45.91s/it]Global seed set to 0\n",
      "2it [01:26, 42.60s/it]Global seed set to 0\n",
      "3it [02:03, 40.27s/it]Global seed set to 0\n",
      "4it [02:43, 40.07s/it]Global seed set to 0\n",
      "5it [03:24, 40.53s/it]Global seed set to 0\n",
      "6it [04:05, 40.63s/it]Global seed set to 0\n",
      "7it [04:47, 40.96s/it]Global seed set to 0\n",
      "8it [05:28, 40.91s/it]Global seed set to 0\n",
      "9it [06:08, 40.68s/it]Global seed set to 0\n",
      "10it [06:48, 40.56s/it]Global seed set to 0\n",
      "11it [07:29, 40.65s/it]Global seed set to 0\n",
      "12it [08:11, 41.00s/it]Global seed set to 0\n",
      "13it [08:52, 41.22s/it]Global seed set to 0\n",
      "14it [09:33, 41.00s/it]Global seed set to 0\n",
      "15it [10:14, 41.13s/it]Global seed set to 0\n",
      "16it [10:55, 40.88s/it]Global seed set to 0\n",
      "17it [11:36, 41.06s/it]Global seed set to 0\n",
      "18it [12:18, 41.16s/it]Global seed set to 0\n",
      "19it [13:00, 41.58s/it]Global seed set to 0\n",
      "20it [13:41, 41.43s/it]Global seed set to 0\n",
      "21it [14:23, 41.52s/it]Global seed set to 0\n",
      "22it [15:05, 41.60s/it]Global seed set to 0\n",
      "23it [15:44, 41.01s/it]Global seed set to 0\n",
      "24it [16:26, 41.08s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "epochs = 2\n",
    "\n",
    "results = []\n",
    "for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "\n",
    "    synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "    synth_dls = []\n",
    "    for i in range(synth_time_series.shape[0]):\n",
    "        synth_dl, *_ = create_ts_dl(synth_time_series[i].reshape(- 1, 1), synth_time_series[i], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=None,\\\n",
    "                                            val_size=0, test_size=0, drop_last=drop_last)\n",
    "        synth_dls.append(synth_dl)\n",
    "    \n",
    "    model = RNNModel(seed=0, device=device)\n",
    "    model.set_model(SimpleLSTM, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    # only synth data\n",
    "    cdl = CombinedDataLoader(*synth_dls)\n",
    "    model.train(cdl, epochs=epochs, print_info=verbose, keep_hs=keep_hs, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.05333846993744373, 'val': 0.10541445016860962},\n",
       " {'train': 0.037882319341103234, 'val': 0.059613317251205444},\n",
       " {'train': 0.007252447151889403, 'val': 0.005394076928496361},\n",
       " {'train': 0.01003556822737058, 'val': 0.010693907737731934},\n",
       " {'train': 0.016704676672816277, 'val': 0.014040783047676086},\n",
       " {'train': 0.028331669978797436, 'val': 0.028229130432009697},\n",
       " {'train': 0.029098593071103095, 'val': 0.03820819780230522},\n",
       " {'train': 0.017204161174595355, 'val': 0.015449265949428082},\n",
       " {'train': 0.008985073616107305, 'val': 0.0061752330511808395},\n",
       " {'train': 0.008392451517283916, 'val': 0.007161007262766361},\n",
       " {'train': 0.054158644957674876, 'val': 0.039467787370085716},\n",
       " {'train': 0.03755103134446674, 'val': 0.021011995151638985},\n",
       " {'train': 0.03527219076123503, 'val': 0.03197217732667923},\n",
       " {'train': 0.011848160065710545, 'val': 0.0066019208170473576},\n",
       " {'train': 0.018985438998788594, 'val': 0.010308427270501852},\n",
       " {'train': 0.042418853379786015, 'val': 0.027426238171756268},\n",
       " {'train': 0.02931434085423296, 'val': 0.02164387982338667},\n",
       " {'train': 0.00676138305359266, 'val': 0.006632580421864986},\n",
       " {'train': 0.01839676998894323, 'val': 0.01729364786297083},\n",
       " {'train': 0.009603568818420172, 'val': 0.005847470136359334},\n",
       " {'train': 0.015256465522964535, 'val': 0.007396668794431857},\n",
       " {'train': 0.00890746550867334, 'val': 0.006716820353176445},\n",
       " {'train': 0.02336570349238489, 'val': 0.028431347105652094},\n",
       " {'train': 0.018278725469779027, 'val': 0.00874813657719642}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\FourierFlow_synth_LSTM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with RealNVP synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Global seed set to 0\n",
      "1it [00:47, 47.49s/it]Global seed set to 0\n",
      "2it [01:27, 42.86s/it]Global seed set to 0\n",
      "3it [02:04, 40.57s/it]Global seed set to 0\n",
      "4it [02:44, 40.07s/it]Global seed set to 0\n",
      "5it [03:22, 39.27s/it]Global seed set to 0\n",
      "6it [04:02, 39.82s/it]Global seed set to 0\n",
      "7it [04:46, 41.16s/it]Global seed set to 0\n",
      "8it [05:31, 42.39s/it]Global seed set to 0\n",
      "9it [06:15, 42.82s/it]Global seed set to 0\n",
      "10it [07:00, 43.29s/it]Global seed set to 0\n",
      "11it [07:43, 43.49s/it]Global seed set to 0\n",
      "12it [08:27, 43.55s/it]Global seed set to 0\n",
      "13it [09:12, 43.83s/it]Global seed set to 0\n",
      "14it [09:56, 44.06s/it]Global seed set to 0\n",
      "15it [10:41, 44.36s/it]Global seed set to 0\n",
      "16it [11:25, 44.09s/it]Global seed set to 0\n",
      "17it [12:09, 44.14s/it]Global seed set to 0\n",
      "18it [12:54, 44.35s/it]Global seed set to 0\n",
      "19it [13:38, 44.32s/it]Global seed set to 0\n",
      "20it [14:23, 44.37s/it]Global seed set to 0\n",
      "21it [15:07, 44.37s/it]Global seed set to 0\n",
      "22it [15:52, 44.51s/it]Global seed set to 0\n",
      "23it [16:36, 44.51s/it]Global seed set to 0\n",
      "24it [17:22, 43.43s/it]\n"
     ]
    }
   ],
   "source": [
    "synthetic_path = f\"{dataset_path}synthetic/RealNVP/\"\n",
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "epochs = 2\n",
    "\n",
    "results = []\n",
    "for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "    train_dl, val_dl, test_dl, X_scaler, y_scaler = create_ts_dl(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=\"log_returns\",\\\n",
    "                                            val_size=val_size, test_size=test_size, drop_last=drop_last)\n",
    "\n",
    "    synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "    synth_dls = []\n",
    "    for i in range(synth_time_series.shape[0]):\n",
    "        synth_dl, *_ = create_ts_dl(synth_time_series[i].reshape(- 1, 1), synth_time_series[i], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            batch_size=batch_size, device=device, data_preprocess=None,\\\n",
    "                                            val_size=0, test_size=0, drop_last=drop_last)\n",
    "        synth_dls.append(synth_dl)\n",
    "    \n",
    "    model = RNNModel(seed=0, device=device)\n",
    "    model.set_model(SimpleLSTM, **model_params)\n",
    "    optim_params = {'params': model.model.parameters(), 'lr': 4e-4}\n",
    "    model.set_optim(torch.optim.AdamW, **optim_params)\n",
    "    model.set_criterion(MAE)\n",
    "\n",
    "    # only synth data\n",
    "    cdl = CombinedDataLoader(*synth_dls)\n",
    "    model.train(cdl, epochs=epochs, print_info=verbose, keep_hs=keep_hs, agg_loss=\"mean\")\n",
    "    results.append({\"train\": model.eval(train_dl, agg_loss=\"mean\"), \"val\": model.eval(val_dl, agg_loss=\"mean\")})\n",
    "\n",
    "    del model, train_dl, val_dl, test_dl\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.020134223625063896, 'val': 0.11028391122817993},\n",
       " {'train': 0.0347943144539992, 'val': 0.05796701833605766},\n",
       " {'train': 0.007007423633088668, 'val': 0.00516876857727766},\n",
       " {'train': 0.00960927518705527, 'val': 0.010699539445340633},\n",
       " {'train': 0.015775732696056366, 'val': 0.013453226536512375},\n",
       " {'train': 0.027417889796197414, 'val': 0.02723686397075653},\n",
       " {'train': 0.027957553416490553, 'val': 0.0374186672270298},\n",
       " {'train': 0.01665698438882828, 'val': 0.015259279869496822},\n",
       " {'train': 0.008629022554183999, 'val': 0.006125194253399968},\n",
       " {'train': 0.008007310424000024, 'val': 0.006995756179094315},\n",
       " {'train': 0.05247532203793526, 'val': 0.038463592529296875},\n",
       " {'train': 0.03685981076624659, 'val': 0.02092783711850643},\n",
       " {'train': 0.034750730006231204, 'val': 0.03208211809396744},\n",
       " {'train': 0.011692417087033391, 'val': 0.006526415701955557},\n",
       " {'train': 0.018525396659970283, 'val': 0.010269255377352238},\n",
       " {'train': 0.04204504042863846, 'val': 0.027379087172448635},\n",
       " {'train': 0.02868534675375982, 'val': 0.021622558124363422},\n",
       " {'train': 0.006653822916136546, 'val': 0.006403734907507896},\n",
       " {'train': 0.0181097812442617, 'val': 0.01687993574887514},\n",
       " {'train': 0.009192070077088747, 'val': 0.005484064808115363},\n",
       " {'train': 0.01473303995781431, 'val': 0.0072429681728993145},\n",
       " {'train': 0.008717047201935202, 'val': 0.006693664065096527},\n",
       " {'train': 0.023267596028745174, 'val': 0.028295948635786772},\n",
       " {'train': 0.018116073045683533, 'val': 0.008615844300948083}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\RealNVP_synth_LSTM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
