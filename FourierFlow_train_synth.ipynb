{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from utils.data import get_hsm_dataset, split_data, log_returns\n",
    "from utils.metrics import MAPE, WAPE, MAE\n",
    "\n",
    "from fourier_flows.SequentialFlows import FourierFlow, RealNVP, TimeFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\"\n",
    "synthetic_path = f\"{dataset_path}synthetic/FourierFlow/\"\n",
    "models_dir = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "val_size = 0.15\n",
    "test_size = 0.0\n",
    "\n",
    "T = 127\n",
    "n_samples = 1600 * 127  # number of samples generated by QuantGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #0\n",
      "step: 0 \t/ 50 \t-\tloss: 473.580\n",
      "step: 49 \t/ 50 \t|\tloss: -2398.528\n",
      "Finished training!\n",
      "Time Series #1\n",
      "step: 0 \t/ 50 \t-\tloss: 1005.193\n",
      "step: 49 \t/ 50 \t|\tloss: -5915.730\n",
      "Finished training!\n",
      "Time Series #2\n",
      "step: 0 \t/ 50 \t-\tloss: 912.041\n",
      "step: 49 \t/ 50 \t|\tloss: -7006.384\n",
      "Finished training!\n",
      "Time Series #3\n",
      "step: 0 \t/ 50 \t-\tloss: 794.596\n",
      "step: 49 \t/ 50 \t|\tloss: -5858.341\n",
      "Finished training!\n",
      "Time Series #4\n",
      "step: 0 \t/ 50 \t-\tloss: 643.179\n",
      "step: 49 \t/ 50 \t|\tloss: -4312.153\n",
      "Finished training!\n",
      "Time Series #5\n",
      "step: 0 \t/ 50 \t-\tloss: 1800.049\n",
      "step: 49 \t/ 50 \t|\tloss: -12257.492\n",
      "Finished training!\n",
      "Time Series #6\n",
      "step: 0 \t/ 50 \t-\tloss: 1323.650\n",
      "step: 49 \t/ 50 \t|\tloss: -9180.222\n",
      "Finished training!\n",
      "Time Series #7\n",
      "step: 0 \t/ 50 \t-\tloss: 1501.057\n",
      "step: 49 \t/ 50 \t|\tloss: -10624.238\n",
      "Finished training!\n",
      "Time Series #8\n",
      "step: 0 \t/ 50 \t-\tloss: 1872.619\n",
      "step: 49 \t/ 50 \t|\tloss: -14972.262\n",
      "Finished training!\n",
      "Time Series #9\n",
      "step: 0 \t/ 50 \t-\tloss: 1567.120\n",
      "step: 49 \t/ 50 \t|\tloss: -11942.075\n",
      "Finished training!\n",
      "Time Series #10\n",
      "step: 0 \t/ 50 \t-\tloss: 2797.664\n",
      "step: 49 \t/ 50 \t|\tloss: -18083.064\n",
      "Finished training!\n",
      "Time Series #11\n",
      "step: 0 \t/ 50 \t-\tloss: 2926.299\n",
      "step: 49 \t/ 50 \t|\tloss: -19465.430\n",
      "Finished training!\n",
      "Time Series #12\n",
      "step: 0 \t/ 50 \t-\tloss: 2725.052\n",
      "step: 49 \t/ 50 \t|\tloss: -19053.352\n",
      "Finished training!\n",
      "Time Series #13\n",
      "step: 0 \t/ 50 \t-\tloss: 2435.714\n",
      "step: 49 \t/ 50 \t|\tloss: -18315.562\n",
      "Finished training!\n",
      "Time Series #14\n",
      "step: 0 \t/ 50 \t-\tloss: 3082.351\n",
      "step: 49 \t/ 50 \t|\tloss: -22177.555\n",
      "Finished training!\n",
      "Time Series #15\n",
      "step: 0 \t/ 50 \t-\tloss: 3165.766\n",
      "step: 49 \t/ 50 \t|\tloss: -21071.760\n",
      "Finished training!\n",
      "Time Series #16\n",
      "step: 0 \t/ 50 \t-\tloss: 3378.161\n",
      "step: 49 \t/ 50 \t|\tloss: -23132.770\n",
      "Finished training!\n",
      "Time Series #17\n",
      "step: 0 \t/ 50 \t-\tloss: 3333.434\n",
      "step: 49 \t/ 50 \t|\tloss: -26259.979\n",
      "Finished training!\n",
      "Time Series #18\n",
      "step: 0 \t/ 50 \t-\tloss: 3297.954\n",
      "step: 49 \t/ 50 \t|\tloss: -24547.188\n",
      "Finished training!\n",
      "Time Series #19\n",
      "step: 0 \t/ 50 \t-\tloss: 3334.502\n",
      "step: 49 \t/ 50 \t|\tloss: -25857.078\n",
      "Finished training!\n",
      "Time Series #20\n",
      "step: 0 \t/ 50 \t-\tloss: 12018.905\n",
      "step: 49 \t/ 50 \t|\tloss: -87749.188\n",
      "Finished training!\n",
      "Time Series #21\n",
      "step: 0 \t/ 50 \t-\tloss: 12713.698\n",
      "step: 49 \t/ 50 \t|\tloss: -94695.828\n",
      "Finished training!\n",
      "Time Series #22\n",
      "step: 0 \t/ 50 \t-\tloss: 7055.556\n",
      "step: 49 \t/ 50 \t|\tloss: -51416.062\n",
      "Finished training!\n",
      "Time Series #23\n",
      "step: 0 \t/ 50 \t-\tloss: 5819.179\n",
      "step: 49 \t/ 50 \t|\tloss: -42170.520\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "seed_everything(0)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    \n",
    "    (train_ts, *_), *_ = split_data(time_series, val_size=val_size, test_size=test_size)\n",
    "    train_ts = log_returns(train_ts)\n",
    "    train_ts = train_ts[:(len(train_ts) // 4 * 4 + 1 if len(train_ts) % 4 > 0 else len(train_ts) - 3)]\n",
    "\n",
    "    FF_model = FourierFlow(hidden=200, fft_size=len(train_ts), n_flows=10, normalize=False)\n",
    "\n",
    "    FF_losses = FF_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n",
    "                            learning_rate=1e-3, display_step=50)\n",
    "\n",
    "    synth_data = FF_model.sample(n_samples // len(train_ts))\n",
    "    np.save(synthetic_path + f\"selected{ts_index}.npy\", synth_data)\n",
    "\n",
    "    del train_ts, synth_data, FF_model, FF_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealNVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #0\n",
      "step: 0 \t/ 50 \t-\tloss: 465.672\n",
      "step: 49 \t/ 50 \t|\tloss: -1702.540\n",
      "Finished training!\n",
      "Time Series #1\n",
      "step: 0 \t/ 50 \t-\tloss: 965.470\n",
      "step: 49 \t/ 50 \t|\tloss: -3922.813\n",
      "Finished training!\n",
      "Time Series #2\n",
      "step: 0 \t/ 50 \t-\tloss: 935.177\n",
      "step: 49 \t/ 50 \t|\tloss: -5050.912\n",
      "Finished training!\n",
      "Time Series #3\n",
      "step: 0 \t/ 50 \t-\tloss: 804.124\n",
      "step: 49 \t/ 50 \t|\tloss: -3909.104\n",
      "Finished training!\n",
      "Time Series #4\n",
      "step: 0 \t/ 50 \t-\tloss: 673.769\n",
      "step: 49 \t/ 50 \t|\tloss: -2838.981\n",
      "Finished training!\n",
      "Time Series #5\n",
      "step: 0 \t/ 50 \t-\tloss: 1795.220\n",
      "step: 49 \t/ 50 \t|\tloss: -8463.556\n",
      "Finished training!\n",
      "Time Series #6\n",
      "step: 0 \t/ 50 \t-\tloss: 1314.388\n",
      "step: 49 \t/ 50 \t|\tloss: -6345.308\n",
      "Finished training!\n",
      "Time Series #7\n",
      "step: 0 \t/ 50 \t-\tloss: 1500.876\n",
      "step: 49 \t/ 50 \t|\tloss: -6804.180\n",
      "Finished training!\n",
      "Time Series #8\n",
      "step: 0 \t/ 50 \t-\tloss: 1859.555\n",
      "step: 49 \t/ 50 \t|\tloss: -9526.939\n",
      "Finished training!\n",
      "Time Series #9\n",
      "step: 0 \t/ 50 \t-\tloss: 1563.881\n",
      "step: 49 \t/ 50 \t|\tloss: -7943.099\n",
      "Finished training!\n",
      "Time Series #10\n",
      "step: 0 \t/ 50 \t-\tloss: 2820.188\n",
      "step: 49 \t/ 50 \t|\tloss: -13341.747\n",
      "Finished training!\n",
      "Time Series #11\n",
      "step: 0 \t/ 50 \t-\tloss: 2813.828\n",
      "step: 49 \t/ 50 \t|\tloss: -11706.519\n",
      "Finished training!\n",
      "Time Series #12\n",
      "step: 0 \t/ 50 \t-\tloss: 2751.986\n",
      "step: 49 \t/ 50 \t|\tloss: -11196.076\n",
      "Finished training!\n",
      "Time Series #13\n",
      "step: 0 \t/ 50 \t-\tloss: 2459.974\n",
      "step: 49 \t/ 50 \t|\tloss: -11477.133\n",
      "Finished training!\n",
      "Time Series #14\n",
      "step: 0 \t/ 50 \t-\tloss: 2968.794\n",
      "step: 49 \t/ 50 \t|\tloss: -13089.045\n",
      "Finished training!\n",
      "Time Series #15\n",
      "step: 0 \t/ 50 \t-\tloss: 3224.469\n",
      "step: 49 \t/ 50 \t|\tloss: -14289.583\n",
      "Finished training!\n",
      "Time Series #16\n",
      "step: 0 \t/ 50 \t-\tloss: 3387.849\n",
      "step: 49 \t/ 50 \t|\tloss: -14842.388\n",
      "Finished training!\n",
      "Time Series #17\n",
      "step: 0 \t/ 50 \t-\tloss: 3304.432\n",
      "step: 49 \t/ 50 \t|\tloss: -17702.943\n",
      "Finished training!\n",
      "Time Series #18\n",
      "step: 0 \t/ 50 \t-\tloss: 3302.665\n",
      "step: 49 \t/ 50 \t|\tloss: -14461.260\n",
      "Finished training!\n",
      "Time Series #19\n",
      "step: 0 \t/ 50 \t-\tloss: 3344.774\n",
      "step: 49 \t/ 50 \t|\tloss: -16693.707\n",
      "Finished training!\n",
      "Time Series #20\n",
      "step: 0 \t/ 50 \t-\tloss: 12053.860\n",
      "step: 49 \t/ 50 \t|\tloss: -72436.062\n",
      "Finished training!\n",
      "Time Series #21\n",
      "step: 0 \t/ 50 \t-\tloss: 12515.731\n",
      "step: 49 \t/ 50 \t|\tloss: -70460.844\n",
      "Finished training!\n",
      "Time Series #22\n",
      "step: 0 \t/ 50 \t-\tloss: 7021.306\n",
      "step: 49 \t/ 50 \t|\tloss: -28109.090\n",
      "Finished training!\n",
      "Time Series #23\n",
      "step: 0 \t/ 50 \t-\tloss: 5796.221\n",
      "step: 49 \t/ 50 \t|\tloss: -24146.781\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "synthetic_path = synthetic_path = f\"{dataset_path}synthetic/RealNVP/\"\n",
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "seed_everything(0)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    \n",
    "    (train_ts, *_), *_ = split_data(time_series, val_size=val_size, test_size=test_size)\n",
    "    train_ts = log_returns(train_ts)\n",
    "    train_ts = train_ts[:(len(train_ts) // 4 * 4 + 1 if len(train_ts) % 4 > 0 else len(train_ts) - 3)]\n",
    "\n",
    "    RealNVP_model = RealNVP(hidden=200, T=len(train_ts), n_flows=10, normalize=False)\n",
    "\n",
    "    RealNVP_losses = RealNVP_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n",
    "                            learning_rate=1e-3, display_step=50)\n",
    "\n",
    "    synth_data = RealNVP_model.sample(n_samples // len(train_ts))\n",
    "    np.save(synthetic_path + f\"selected{ts_index}.npy\", synth_data)\n",
    "\n",
    "    del train_ts, synth_data, RealNVP_model, RealNVP_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time: 5:37.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #0\n",
      "step: 0 \t/ 50 \t-\tloss: 454.488\n",
      "step: 49 \t/ 50 \t|\tloss: -1629.545\n",
      "Finished training!\n",
      "Time Series #1\n",
      "step: 0 \t/ 50 \t-\tloss: 938.817\n",
      "step: 49 \t/ 50 \t|\tloss: -4023.636\n",
      "Finished training!\n",
      "Time Series #2\n",
      "step: 0 \t/ 50 \t-\tloss: 890.112\n",
      "step: 49 \t/ 50 \t|\tloss: -5208.440\n",
      "Finished training!\n",
      "Time Series #3\n",
      "step: 0 \t/ 50 \t-\tloss: 781.526\n",
      "step: 49 \t/ 50 \t|\tloss: -3923.052\n",
      "Finished training!\n",
      "Time Series #4\n",
      "step: 0 \t/ 50 \t-\tloss: 620.486\n",
      "step: 49 \t/ 50 \t|\tloss: -2865.744\n",
      "Finished training!\n",
      "Time Series #5\n",
      "step: 0 \t/ 50 \t-\tloss: 1754.506\n",
      "step: 49 \t/ 50 \t|\tloss: -8762.397\n",
      "Finished training!\n",
      "Time Series #6\n",
      "step: 0 \t/ 50 \t-\tloss: 1332.166\n",
      "step: 49 \t/ 50 \t|\tloss: -6392.702\n",
      "Finished training!\n",
      "Time Series #7\n",
      "step: 0 \t/ 50 \t-\tloss: 1433.448\n",
      "step: 49 \t/ 50 \t|\tloss: -6861.422\n",
      "Finished training!\n",
      "Time Series #8\n",
      "step: 0 \t/ 50 \t-\tloss: 1873.701\n",
      "step: 49 \t/ 50 \t|\tloss: -9757.703\n",
      "Finished training!\n",
      "Time Series #9\n",
      "step: 0 \t/ 50 \t-\tloss: 1506.357\n",
      "step: 49 \t/ 50 \t|\tloss: -7991.845\n",
      "Finished training!\n",
      "Time Series #10\n",
      "step: 0 \t/ 50 \t-\tloss: 2804.562\n",
      "step: 49 \t/ 50 \t|\tloss: -13349.042\n",
      "Finished training!\n",
      "Time Series #11\n",
      "step: 0 \t/ 50 \t-\tloss: 2860.076\n",
      "step: 49 \t/ 50 \t|\tloss: -12040.274\n",
      "Finished training!\n",
      "Time Series #12\n",
      "step: 0 \t/ 50 \t-\tloss: 2729.591\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14332/2138942507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mTimeFlow_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeFlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_flows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     TimeFlow_losses = TimeFlow_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n\u001b[0m\u001b[0;32m     15\u001b[0m                             learning_rate=1e-3, display_step=50)\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\fourier_flows\\SequentialFlows.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, epochs, batch_size, learning_rate, display_step)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "synthetic_path = synthetic_path = f\"{dataset_path}synthetic/TimeFlow/\"\n",
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "seed_everything(0)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    \n",
    "    (train_ts, *_), *_ = split_data(time_series, val_size=val_size, test_size=test_size)\n",
    "    train_ts = log_returns(train_ts)\n",
    "    train_ts = train_ts[:(len(train_ts) // 4 * 4 + 1 if len(train_ts) % 4 > 0 else len(train_ts) - 3)]\n",
    "\n",
    "    TimeFlow_model = TimeFlow(hidden=200, T=len(train_ts), n_flows=10, normalize=False)\n",
    "\n",
    "    TimeFlow_losses = TimeFlow_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n",
    "                            learning_rate=1e-3, display_step=50)\n",
    "\n",
    "    synth_data = TimeFlow_model.sample(n_samples // len(train_ts))\n",
    "    np.save(synthetic_path + f\"selected{ts_index}.npy\", synth_data)\n",
    "\n",
    "    del train_ts, synth_data, TimeFlow_model, TimeFlow_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 ts time: ~30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
