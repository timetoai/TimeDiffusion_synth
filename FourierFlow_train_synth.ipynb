{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from utils.data import get_hsm_dataset, split_data, log_returns\n",
    "from utils.metrics import MAPE, WAPE, MAE\n",
    "\n",
    "from fourier_flows.SequentialFlows import FourierFlow, RealNVP, TimeFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\"\n",
    "synthetic_path = f\"{dataset_path}synthetic/FourierFlow/\"\n",
    "models_dir = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "val_size = 0.0\n",
    "test_size = 0.3\n",
    "\n",
    "T = 127\n",
    "n_samples = 1600 * 127  # number of samples generated by QuantGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #0\n",
      "step: 0 \t/ 50 \t-\tloss: 386.364\n",
      "step: 49 \t/ 50 \t|\tloss: -1892.182\n",
      "Finished training!\n",
      "Time Series #1\n",
      "step: 0 \t/ 50 \t-\tloss: 778.142\n",
      "step: 49 \t/ 50 \t|\tloss: -4973.083\n",
      "Finished training!\n",
      "Time Series #2\n",
      "step: 0 \t/ 50 \t-\tloss: 795.150\n",
      "step: 49 \t/ 50 \t|\tloss: -5734.431\n",
      "Finished training!\n",
      "Time Series #3\n",
      "step: 0 \t/ 50 \t-\tloss: 672.038\n",
      "step: 49 \t/ 50 \t|\tloss: -4722.202\n",
      "Finished training!\n",
      "Time Series #4\n",
      "step: 0 \t/ 50 \t-\tloss: 535.835\n",
      "step: 49 \t/ 50 \t|\tloss: -3467.864\n",
      "Finished training!\n",
      "Time Series #5\n",
      "step: 0 \t/ 50 \t-\tloss: 1487.181\n",
      "step: 49 \t/ 50 \t|\tloss: -10080.338\n",
      "Finished training!\n",
      "Time Series #6\n",
      "step: 0 \t/ 50 \t-\tloss: 1054.862\n",
      "step: 49 \t/ 50 \t|\tloss: -7514.502\n",
      "Finished training!\n",
      "Time Series #7\n",
      "step: 0 \t/ 50 \t-\tloss: 1238.732\n",
      "step: 49 \t/ 50 \t|\tloss: -8594.308\n",
      "Finished training!\n",
      "Time Series #8\n",
      "step: 0 \t/ 50 \t-\tloss: 1549.401\n",
      "step: 49 \t/ 50 \t|\tloss: -12172.836\n",
      "Finished training!\n",
      "Time Series #9\n",
      "step: 0 \t/ 50 \t-\tloss: 1218.759\n",
      "step: 49 \t/ 50 \t|\tloss: -9871.307\n",
      "Finished training!\n",
      "Time Series #10\n",
      "step: 0 \t/ 50 \t-\tloss: 2309.772\n",
      "step: 49 \t/ 50 \t|\tloss: -15222.114\n",
      "Finished training!\n",
      "Time Series #11\n",
      "step: 0 \t/ 50 \t-\tloss: 2355.605\n",
      "step: 49 \t/ 50 \t|\tloss: -15610.852\n",
      "Finished training!\n",
      "Time Series #12\n",
      "step: 0 \t/ 50 \t-\tloss: 2294.040\n",
      "step: 49 \t/ 50 \t|\tloss: -15439.746\n",
      "Finished training!\n",
      "Time Series #13\n",
      "step: 0 \t/ 50 \t-\tloss: 1994.692\n",
      "step: 49 \t/ 50 \t|\tloss: -14892.511\n",
      "Finished training!\n",
      "Time Series #14\n",
      "step: 0 \t/ 50 \t-\tloss: 2440.121\n",
      "step: 49 \t/ 50 \t|\tloss: -17784.570\n",
      "Finished training!\n",
      "Time Series #15\n",
      "step: 0 \t/ 50 \t-\tloss: 2650.768\n",
      "step: 49 \t/ 50 \t|\tloss: -17284.189\n",
      "Finished training!\n",
      "Time Series #16\n",
      "step: 0 \t/ 50 \t-\tloss: 2760.493\n",
      "step: 49 \t/ 50 \t|\tloss: -19522.326\n",
      "Finished training!\n",
      "Time Series #17\n",
      "step: 0 \t/ 50 \t-\tloss: 2744.228\n",
      "step: 49 \t/ 50 \t|\tloss: -21645.430\n",
      "Finished training!\n",
      "Time Series #18\n",
      "step: 0 \t/ 50 \t-\tloss: 2761.680\n",
      "step: 49 \t/ 50 \t|\tloss: -20127.617\n",
      "Finished training!\n",
      "Time Series #19\n",
      "step: 0 \t/ 50 \t-\tloss: 2751.604\n",
      "step: 49 \t/ 50 \t|\tloss: -21670.852\n",
      "Finished training!\n",
      "Time Series #20\n",
      "step: 0 \t/ 50 \t-\tloss: 9797.335\n",
      "step: 49 \t/ 50 \t|\tloss: -66106.023\n",
      "Finished training!\n",
      "Time Series #21\n",
      "step: 0 \t/ 50 \t-\tloss: 10415.761\n",
      "step: 49 \t/ 50 \t|\tloss: -71332.766\n",
      "Finished training!\n",
      "Time Series #22\n",
      "step: 0 \t/ 50 \t-\tloss: 5857.050\n",
      "step: 49 \t/ 50 \t|\tloss: -41759.613\n",
      "Finished training!\n",
      "Time Series #23\n",
      "step: 0 \t/ 50 \t-\tloss: 4689.142\n",
      "step: 49 \t/ 50 \t|\tloss: -34526.312\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "seed_everything(0)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    \n",
    "    (train_ts, *_), *_ = split_data(time_series, val_size=val_size, test_size=test_size)\n",
    "    train_ts = log_returns(train_ts)\n",
    "    train_ts = train_ts[:(len(train_ts) // 4 * 4 + 1 if len(train_ts) % 4 > 0 else len(train_ts) - 3)]\n",
    "\n",
    "    FF_model = FourierFlow(hidden=200, fft_size=len(train_ts), n_flows=10, normalize=False)\n",
    "\n",
    "    FF_losses = FF_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n",
    "                            learning_rate=1e-3, display_step=50)\n",
    "\n",
    "    synth_data = FF_model.sample(n_samples // len(train_ts))\n",
    "    np.save(synthetic_path + f\"selected{ts_index}.npy\", synth_data)\n",
    "\n",
    "    del train_ts, synth_data, FF_model, FF_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4:15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealNVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #0\n",
      "step: 0 \t/ 50 \t-\tloss: 405.040\n",
      "step: 49 \t/ 50 \t|\tloss: -1359.304\n",
      "Finished training!\n",
      "Time Series #1\n",
      "step: 0 \t/ 50 \t-\tloss: 786.542\n",
      "step: 49 \t/ 50 \t|\tloss: -3289.140\n",
      "Finished training!\n",
      "Time Series #2\n",
      "step: 0 \t/ 50 \t-\tloss: 768.657\n",
      "step: 49 \t/ 50 \t|\tloss: -4175.608\n",
      "Finished training!\n",
      "Time Series #3\n",
      "step: 0 \t/ 50 \t-\tloss: 640.137\n",
      "step: 49 \t/ 50 \t|\tloss: -3085.500\n",
      "Finished training!\n",
      "Time Series #4\n",
      "step: 0 \t/ 50 \t-\tloss: 504.549\n",
      "step: 49 \t/ 50 \t|\tloss: -2321.648\n",
      "Finished training!\n",
      "Time Series #5\n",
      "step: 0 \t/ 50 \t-\tloss: 1436.041\n",
      "step: 49 \t/ 50 \t|\tloss: -7238.917\n",
      "Finished training!\n",
      "Time Series #6\n",
      "step: 0 \t/ 50 \t-\tloss: 1072.026\n",
      "step: 49 \t/ 50 \t|\tloss: -5224.252\n",
      "Finished training!\n",
      "Time Series #7\n",
      "step: 0 \t/ 50 \t-\tloss: 1202.877\n",
      "step: 49 \t/ 50 \t|\tloss: -5593.020\n",
      "Finished training!\n",
      "Time Series #8\n",
      "step: 0 \t/ 50 \t-\tloss: 1530.266\n",
      "step: 49 \t/ 50 \t|\tloss: -7939.487\n",
      "Finished training!\n",
      "Time Series #9\n",
      "step: 0 \t/ 50 \t-\tloss: 1226.088\n",
      "step: 49 \t/ 50 \t|\tloss: -6521.028\n",
      "Finished training!\n",
      "Time Series #10\n",
      "step: 0 \t/ 50 \t-\tloss: 2344.378\n",
      "step: 49 \t/ 50 \t|\tloss: -11074.658\n",
      "Finished training!\n",
      "Time Series #11\n",
      "step: 0 \t/ 50 \t-\tloss: 2300.591\n",
      "step: 49 \t/ 50 \t|\tloss: -9886.137\n",
      "Finished training!\n",
      "Time Series #12\n",
      "step: 0 \t/ 50 \t-\tloss: 2309.661\n",
      "step: 49 \t/ 50 \t|\tloss: -9721.771\n",
      "Finished training!\n",
      "Time Series #13\n",
      "step: 0 \t/ 50 \t-\tloss: 1930.946\n",
      "step: 49 \t/ 50 \t|\tloss: -9509.512\n",
      "Finished training!\n",
      "Time Series #14\n",
      "step: 0 \t/ 50 \t-\tloss: 2437.796\n",
      "step: 49 \t/ 50 \t|\tloss: -11220.389\n",
      "Finished training!\n",
      "Time Series #15\n",
      "step: 0 \t/ 50 \t-\tloss: 2673.794\n",
      "step: 49 \t/ 50 \t|\tloss: -11798.643\n",
      "Finished training!\n",
      "Time Series #16\n",
      "step: 0 \t/ 50 \t-\tloss: 2780.895\n",
      "step: 49 \t/ 50 \t|\tloss: -12219.533\n",
      "Finished training!\n",
      "Time Series #17\n",
      "step: 0 \t/ 50 \t-\tloss: 2791.195\n",
      "step: 49 \t/ 50 \t|\tloss: -15447.723\n",
      "Finished training!\n",
      "Time Series #18\n",
      "step: 0 \t/ 50 \t-\tloss: 2802.860\n",
      "step: 49 \t/ 50 \t|\tloss: -12400.538\n",
      "Finished training!\n",
      "Time Series #19\n",
      "step: 0 \t/ 50 \t-\tloss: 2788.126\n",
      "step: 49 \t/ 50 \t|\tloss: -13928.409\n",
      "Finished training!\n",
      "Time Series #20\n",
      "step: 0 \t/ 50 \t-\tloss: 9827.639\n",
      "step: 49 \t/ 50 \t|\tloss: -62544.762\n",
      "Finished training!\n",
      "Time Series #21\n",
      "step: 0 \t/ 50 \t-\tloss: 10404.473\n",
      "step: 49 \t/ 50 \t|\tloss: -63614.309\n",
      "Finished training!\n",
      "Time Series #22\n",
      "step: 0 \t/ 50 \t-\tloss: 5770.537\n",
      "step: 49 \t/ 50 \t|\tloss: -26270.312\n",
      "Finished training!\n",
      "Time Series #23\n",
      "step: 0 \t/ 50 \t-\tloss: 4674.049\n",
      "step: 49 \t/ 50 \t|\tloss: -20457.723\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "synthetic_path = synthetic_path = f\"{dataset_path}synthetic/RealNVP/\"\n",
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "seed_everything(0)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    \n",
    "    (train_ts, *_), *_ = split_data(time_series, val_size=val_size, test_size=test_size)\n",
    "    train_ts = log_returns(train_ts)\n",
    "    train_ts = train_ts[:(len(train_ts) // 4 * 4 + 1 if len(train_ts) % 4 > 0 else len(train_ts) - 3)]\n",
    "\n",
    "    RealNVP_model = RealNVP(hidden=200, T=len(train_ts), n_flows=10, normalize=False)\n",
    "\n",
    "    RealNVP_losses = RealNVP_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n",
    "                            learning_rate=1e-3, display_step=50)\n",
    "\n",
    "    synth_data = RealNVP_model.sample(n_samples // len(train_ts))\n",
    "    np.save(synthetic_path + f\"selected{ts_index}.npy\", synth_data)\n",
    "\n",
    "    del train_ts, synth_data, RealNVP_model, RealNVP_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time: 4:02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series #0\n",
      "step: 0 \t/ 50 \t-\tloss: 454.488\n",
      "step: 49 \t/ 50 \t|\tloss: -1629.545\n",
      "Finished training!\n",
      "Time Series #1\n",
      "step: 0 \t/ 50 \t-\tloss: 938.817\n",
      "step: 49 \t/ 50 \t|\tloss: -4023.636\n",
      "Finished training!\n",
      "Time Series #2\n",
      "step: 0 \t/ 50 \t-\tloss: 890.112\n",
      "step: 49 \t/ 50 \t|\tloss: -5208.440\n",
      "Finished training!\n",
      "Time Series #3\n",
      "step: 0 \t/ 50 \t-\tloss: 781.526\n",
      "step: 49 \t/ 50 \t|\tloss: -3923.052\n",
      "Finished training!\n",
      "Time Series #4\n",
      "step: 0 \t/ 50 \t-\tloss: 620.486\n",
      "step: 49 \t/ 50 \t|\tloss: -2865.744\n",
      "Finished training!\n",
      "Time Series #5\n",
      "step: 0 \t/ 50 \t-\tloss: 1754.506\n",
      "step: 49 \t/ 50 \t|\tloss: -8762.397\n",
      "Finished training!\n",
      "Time Series #6\n",
      "step: 0 \t/ 50 \t-\tloss: 1332.166\n",
      "step: 49 \t/ 50 \t|\tloss: -6392.702\n",
      "Finished training!\n",
      "Time Series #7\n",
      "step: 0 \t/ 50 \t-\tloss: 1433.448\n",
      "step: 49 \t/ 50 \t|\tloss: -6861.422\n",
      "Finished training!\n",
      "Time Series #8\n",
      "step: 0 \t/ 50 \t-\tloss: 1873.701\n",
      "step: 49 \t/ 50 \t|\tloss: -9757.703\n",
      "Finished training!\n",
      "Time Series #9\n",
      "step: 0 \t/ 50 \t-\tloss: 1506.357\n",
      "step: 49 \t/ 50 \t|\tloss: -7991.845\n",
      "Finished training!\n",
      "Time Series #10\n",
      "step: 0 \t/ 50 \t-\tloss: 2804.562\n",
      "step: 49 \t/ 50 \t|\tloss: -13349.042\n",
      "Finished training!\n",
      "Time Series #11\n",
      "step: 0 \t/ 50 \t-\tloss: 2860.076\n",
      "step: 49 \t/ 50 \t|\tloss: -12040.274\n",
      "Finished training!\n",
      "Time Series #12\n",
      "step: 0 \t/ 50 \t-\tloss: 2729.591\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14332/2138942507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mTimeFlow_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeFlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_flows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     TimeFlow_losses = TimeFlow_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n\u001b[0m\u001b[0;32m     15\u001b[0m                             learning_rate=1e-3, display_step=50)\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Владислав\\Учеба\\Магистратура\\3 семестр\\synthetic data generation\\project\\fourier_flows\\SequentialFlows.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, epochs, batch_size, learning_rate, display_step)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Владислав\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "synthetic_path = synthetic_path = f\"{dataset_path}synthetic/TimeFlow/\"\n",
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "seed_everything(0)\n",
    "\n",
    "for ts_index, time_series in enumerate(ts_iterator):\n",
    "    print(f\"Time Series #{ts_index}\")\n",
    "    \n",
    "    (train_ts, *_), *_ = split_data(time_series, val_size=val_size, test_size=test_size)\n",
    "    train_ts = log_returns(train_ts)\n",
    "    train_ts = train_ts[:(len(train_ts) // 4 * 4 + 1 if len(train_ts) % 4 > 0 else len(train_ts) - 3)]\n",
    "\n",
    "    TimeFlow_model = TimeFlow(hidden=200, T=len(train_ts), n_flows=10, normalize=False)\n",
    "\n",
    "    TimeFlow_losses = TimeFlow_model.fit(train_ts.values.reshape(1, - 1), epochs=50, batch_size=128, \n",
    "                            learning_rate=1e-3, display_step=50)\n",
    "\n",
    "    synth_data = TimeFlow_model.sample(n_samples // len(train_ts))\n",
    "    np.save(synthetic_path + f\"selected{ts_index}.npy\", synth_data)\n",
    "\n",
    "    del train_ts, synth_data, TimeFlow_model, TimeFlow_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 ts time: ~30 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import kl_div\n",
    "\n",
    "from utils.data import get_hsm_dataset, split_data, log_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"data/huge_stock_market_dataset/\")\n",
    "results_dir = Path(\"results\")\n",
    "\n",
    "val_size = 0.0\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_div = lambda x, y: (kl_div(x, (x + y) / 2) + kl_div(y, (x + y) / 2)) / 2\n",
    "min_max_norm = lambda x: (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 25.16it/s]\n",
      "24it [00:00, 25.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in (\"FourierFlow\", \"RealNVP\"):\n",
    "    synthetic_path = dataset_path / f\"synthetic/{model}/\"\n",
    "    results = {\"kl_div\": [], \"sj_div\": []}\n",
    "    ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "    for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "        (train_ts, *_), *_ = split_data(time_series, val_size=val_size, test_size=test_size)\n",
    "        train_ts = log_returns(train_ts)\n",
    "        train_ts = train_ts[:(len(train_ts) // 4 * 4 + 1 if len(train_ts) % 4 > 0 else len(train_ts) - 3)].values.flatten()\n",
    "        train_ts = min_max_norm(train_ts)\n",
    "        \n",
    "        synth_tss = np.load(synthetic_path / f\"selected{ts_index}.npy\")\n",
    "        kl_div_res = sj_div_res = 0\n",
    "        for synth_ts in synth_tss:\n",
    "            synth_ts = min_max_norm(synth_ts)\n",
    "            res = kl_div(synth_ts, train_ts)\n",
    "            kl_div_res += np.where(np.isinf(res), 0, res).mean()\n",
    "            sj_div_res += sj_div(synth_ts, train_ts).mean()\n",
    "        results[\"kl_div\"].append(kl_div_res / len(synth_tss))\n",
    "        results[\"sj_div\"].append(sj_div_res / len(synth_tss))\n",
    "    \n",
    "    pd.DataFrame(results).to_csv(results_dir / f\"synth_sim_{model}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
