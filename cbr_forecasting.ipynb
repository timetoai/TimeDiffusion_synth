{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_error as MAE, mean_absolute_percentage_error as MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 32\n",
    "horizon = 8\n",
    "stride = 1\n",
    "val_size = 0.15\n",
    "test_size = 0.0\n",
    "features = 1\n",
    "\n",
    "model_params = {\"silent\": True, \"random_seed\": 13, 'loss_function': 'MultiRMSE',  'eval_metric': 'MultiRMSE', \"iterations\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [01:30,  3.79s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "results = []\n",
    "for time_series in tqdm(ts_iterator):\n",
    "    (X_train, y_train), (X_val, y_val), _, X_scaler, y_scaler = create_ts(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            data_preprocess=(\"log_returns\", \"normalize\"),\\\n",
    "                                            val_size=val_size, test_size=test_size)\n",
    "    X_train, X_val = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_val))\n",
    "    train_dl = Pool(X_train, label=y_train)\n",
    "    val_dl = Pool(X_val, label=y_val)\n",
    "    \n",
    "    model = CatBoostRegressor(**model_params)\n",
    "    # model.fit(train_dl, eval_set=val_dl, early_stopping_rounds=5, use_best_model=True)\n",
    "    model.fit(train_dl)\n",
    "    results.append({\"train\": MAE(y_train, model.predict(X_train)), \"val\": MAE(y_val, model.predict(X_val))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': 0.4721138800789576, 'val': 0.4198577080365975},\n",
       " {'train': 0.4927910753616652, 'val': 0.7000470996421194},\n",
       " {'train': 0.611703930759554, 'val': 0.4944795815417712},\n",
       " {'train': 0.6220227366896259, 'val': 0.7217822417316845},\n",
       " {'train': 0.5644592305281493, 'val': 0.5149637611398229},\n",
       " {'train': 0.5818978325923387, 'val': 0.5878597190703397},\n",
       " {'train': 0.5740474813297128, 'val': 0.9084701431820057},\n",
       " {'train': 0.5628409667745751, 'val': 0.5125981812442175},\n",
       " {'train': 0.7076598653906154, 'val': 0.5338263021484075},\n",
       " {'train': 0.7018691782001159, 'val': 0.6471641199813174},\n",
       " {'train': 0.6299630144565079, 'val': 0.5022988728025262},\n",
       " {'train': 0.5808765471192069, 'val': 0.3239468387010491},\n",
       " {'train': 0.5581741874890538, 'val': 0.5630569428483101},\n",
       " {'train': 0.6544736919978776, 'val': 0.3844437681462015},\n",
       " {'train': 0.6498089439971121, 'val': 0.3794468314500749},\n",
       " {'train': 0.5537645440474475, 'val': 0.3584969663275588},\n",
       " {'train': 0.5651671014464634, 'val': 0.4362512548537032},\n",
       " {'train': 0.5823540431899215, 'val': 0.5879498784109352},\n",
       " {'train': 0.6623333148234267, 'val': 0.6401209230408119},\n",
       " {'train': 0.6374959854760843, 'val': 0.404602566033205},\n",
       " {'train': 0.4072406692846552, 'val': 0.1980158069086141},\n",
       " {'train': 0.6148909265497198, 'val': 0.4952084033149963},\n",
       " {'train': 0.6964009966652194, 'val': 0.865132282746808},\n",
       " {'train': 0.4964834110761122, 'val': 0.24714445148170056}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{key: value for key, value in x.items()} for x in results]).to_csv(\"results\\\\pure_cbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with QuantGAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_synth(synthetic_path):\n",
    "    ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "    results = []\n",
    "    for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "        synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "        scaler = DimUniversalStandardScaler()\n",
    "        synth_time_series = scaler.fit_transform(synth_time_series)\n",
    "        X_synth, y_synth = [], []\n",
    "        for i in range(synth_time_series.shape[0]):\n",
    "            (X, y), *_ = create_ts(synth_time_series[i].reshape(- 1, 1), synth_time_series[i].flatten(), lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                data_preprocess=(None,), val_size=0, test_size=0)\n",
    "            X_synth.append(X)\n",
    "            y_synth.append(y)\n",
    "\n",
    "        # using train and synth data\n",
    "        # X_train = np.row_stack((X_train, *X_synth))\n",
    "        # y_train = np.row_stack((y_train, *y_synth))\n",
    "        # using only synth data\n",
    "        X_synth = np.row_stack(X_synth)\n",
    "        y_synth = np.row_stack(y_synth)\n",
    "\n",
    "        \n",
    "        (X_train, y_train), (X_val, y_val), *_ = create_ts(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                data_preprocess=(\"log_returns\", \"normalize\"), val_size=val_size, test_size=test_size, scaler=scaler)\n",
    "        X_train, X_val, X_synth = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_val, X_synth))\n",
    "        \n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(X_synth, y_synth)\n",
    "        results.append({\"train\": MAE(y_train, model.predict(X_train)), \"val\": MAE(y_val, model.predict(X_val))})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:09, 15.40s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.5581620788603382, 'val': 0.42703556650480246},\n",
       " {'train': 0.7406758124535515, 'val': 0.9862884430025866},\n",
       " {'train': 0.7078966500998958, 'val': 0.5058399773633997},\n",
       " {'train': 0.7131427472027942, 'val': 0.722834310710203},\n",
       " {'train': 0.6287411470430859, 'val': 0.4850682318406551},\n",
       " {'train': 0.6676337978540728, 'val': 0.6423952676044954},\n",
       " {'train': 0.7229046373865335, 'val': 1.0700081309955045},\n",
       " {'train': 0.7087365816147391, 'val': 0.5972057723694857},\n",
       " {'train': 0.7726383208810653, 'val': 0.5512092895441913},\n",
       " {'train': 0.7429271469871261, 'val': 0.6329099797144754},\n",
       " {'train': 0.5912808347980893, 'val': 0.45215353034844796},\n",
       " {'train': 0.7076944643460387, 'val': 0.379975456041009},\n",
       " {'train': 0.6497924468330752, 'val': 0.6296742028964557},\n",
       " {'train': 0.7363951925757601, 'val': 0.40995225530310053},\n",
       " {'train': 0.6736557874469855, 'val': 0.38380213233104726},\n",
       " {'train': 0.6291133154739842, 'val': 0.3884693754649044},\n",
       " {'train': 0.6402245644869348, 'val': 0.47968147876775347},\n",
       " {'train': 0.6414783276960822, 'val': 0.6247028511523554},\n",
       " {'train': 0.7179424263417011, 'val': 0.6628212554197424},\n",
       " {'train': 0.6984942348686975, 'val': 0.42586273804526087},\n",
       " {'train': 0.2888786893477918, 'val': 0.1420531016961518},\n",
       " {'train': 0.5236550099619344, 'val': 0.4193742864197625},\n",
       " {'train': 0.7457420865085279, 'val': 0.9072486933222899},\n",
       " {'train': 0.6007841652874246, 'val': 0.2856629192465573}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/QuantGAN/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\QuantGAN_synth_cbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with FourierFlow synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:52, 17.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.472414447407477, 'val': 0.4156479829277657},\n",
       " {'train': 0.4673385304328088, 'val': 0.6777075263474912},\n",
       " {'train': 0.4991501964867769, 'val': 0.3884854344428356},\n",
       " {'train': 0.5576655861371456, 'val': 0.6011950560212238},\n",
       " {'train': 0.5258843738212344, 'val': 0.44704001474100896},\n",
       " {'train': 0.5428999737247002, 'val': 0.5439649640159456},\n",
       " {'train': 0.5497361874432269, 'val': 0.8651841819236795},\n",
       " {'train': 0.5355060595106209, 'val': 0.478801936376283},\n",
       " {'train': 0.6126725190400838, 'val': 0.4482768803656117},\n",
       " {'train': 0.5810299152064772, 'val': 0.512053773543315},\n",
       " {'train': 0.6146213646426646, 'val': 0.48384065519324926},\n",
       " {'train': 0.5564821867522125, 'val': 0.313480507316827},\n",
       " {'train': 0.5462842853676411, 'val': 0.5503344804341775},\n",
       " {'train': 0.5794021248828838, 'val': 0.34392428935947855},\n",
       " {'train': 0.5807505140736255, 'val': 0.3415349530957658},\n",
       " {'train': 0.544800046985519, 'val': 0.3525574584093807},\n",
       " {'train': 0.528634207581134, 'val': 0.40704937354552917},\n",
       " {'train': 0.5037438492872852, 'val': 0.5140104587281425},\n",
       " {'train': 0.6286988854689678, 'val': 0.605672682840968},\n",
       " {'train': 0.5373052565498087, 'val': 0.34196890510990174},\n",
       " {'train': 0.4182823530773326, 'val': 0.2026504842302026},\n",
       " {'train': 0.3942412702353845, 'val': 0.3141626092830401},\n",
       " {'train': 0.6541220444010991, 'val': 0.8117790116441128},\n",
       " {'train': 0.4563462909896075, 'val': 0.23352304789286468}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/FourierFlow/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\FourierFlow_synth_cbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with RealNVP synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:07, 15.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.44821009358717867, 'val': 0.44186669788799765},\n",
       " {'train': 0.4791537119518723, 'val': 0.7253706113054383},\n",
       " {'train': 0.45298236021498317, 'val': 0.3828760573758874},\n",
       " {'train': 0.11602518596493146, 'val': 0.14960830230047859},\n",
       " {'train': 0.4568607497279644, 'val': 0.4710543614091952},\n",
       " {'train': 0.5661806736305175, 'val': 0.5826485279899543},\n",
       " {'train': 0.5957985196085549, 'val': 0.9783628604221273},\n",
       " {'train': 0.5253719510363148, 'val': 0.4972970116294527},\n",
       " {'train': 0.6707809047941136, 'val': 0.5161722885382267},\n",
       " {'train': 0.630413630217284, 'val': 0.5920519216387193},\n",
       " {'train': 0.6169952582650898, 'val': 0.49867989128442475},\n",
       " {'train': 0.5659989214348362, 'val': 0.32666520775471275},\n",
       " {'train': 0.545203580839261, 'val': 0.5571362491156171},\n",
       " {'train': 0.61626152554795, 'val': 0.37075112503965685},\n",
       " {'train': 0.6228740414677943, 'val': 0.37432959479934114},\n",
       " {'train': 0.5477765874814933, 'val': 0.3607418138494773},\n",
       " {'train': 0.5451584024037488, 'val': 0.42850970437934144},\n",
       " {'train': 0.55489662271227, 'val': 0.5779297390911781},\n",
       " {'train': 0.6495161797576092, 'val': 0.6309604956560466},\n",
       " {'train': 0.6058776487095003, 'val': 0.39629027943958595},\n",
       " {'train': 0.3975771949197159, 'val': 0.19366170789126513},\n",
       " {'train': 0.583544695651447, 'val': 0.4700517737992541},\n",
       " {'train': 0.5851223958033737, 'val': 0.7240489221566926},\n",
       " {'train': 0.4745051102694474, 'val': 0.24509456584755646}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/RealNVP/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\RealNVP_synth_cbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with TTS GAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:15, 15.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.5318373800073919, 'val': 0.47435486321322845},\n",
       " {'train': 0.552310526820815, 'val': 0.7156018267812723},\n",
       " {'train': 0.18082850684926596, 'val': 0.14143748897065495},\n",
       " {'train': 0.14219920368833194, 'val': 0.14290718060431443},\n",
       " {'train': 0.2496834139188196, 'val': 0.24814578140820384},\n",
       " {'train': 0.8650025073040402, 'val': 0.8306463221688533},\n",
       " {'train': 0.5960645401342772, 'val': 0.8825077658619218},\n",
       " {'train': 0.99311020198162, 'val': 0.841576871679518},\n",
       " {'train': 0.3040346841236944, 'val': 0.22312216351950925},\n",
       " {'train': 0.3584225118921459, 'val': 0.3104392233254107},\n",
       " {'train': 1.0887808582860332, 'val': 0.833868502798798},\n",
       " {'train': 0.8541232137071266, 'val': 0.4558378820328849},\n",
       " {'train': 0.7509940133435706, 'val': 0.7264380723573328},\n",
       " {'train': 0.7870810101250203, 'val': 0.4452968160722733},\n",
       " {'train': 0.8774430891577936, 'val': 0.4882315839081644},\n",
       " {'train': 0.7709750559275947, 'val': 0.476199793057011},\n",
       " {'train': 0.8416773935757502, 'val': 0.6316572125173803},\n",
       " {'train': 0.5274816763377684, 'val': 0.5102570833596733},\n",
       " {'train': 2.1303889850355553, 'val': 1.9760942455668191},\n",
       " {'train': 0.7177710928966948, 'val': 0.434186533851264},\n",
       " {'train': 0.28915130003478534, 'val': 0.2891513248818436},\n",
       " {'train': 1.2921954847618131, 'val': 1.0289376754221617},\n",
       " {'train': 2.6586892284876837, 'val': 3.1802257246457954},\n",
       " {'train': 1.3072460607192888, 'val': 0.6195415917412634}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/TTS_GAN_standard/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results\\\\TTS_GAN_synth_cbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
