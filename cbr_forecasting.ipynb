{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_error as MAE, mean_absolute_percentage_error as MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/huge_stock_market_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 32\n",
    "horizon = 8\n",
    "stride = 1\n",
    "val_size = 0.0\n",
    "test_size = 0.3\n",
    "features = 1\n",
    "\n",
    "model_params = {\"silent\": True, \"random_seed\": 13, 'loss_function': 'MultiRMSE',  'eval_metric': 'MultiRMSE', \"iterations\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [01:28,  3.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.4551696792367407, 'val': 0.460470602310324},\n",
       " {'train': 0.5409159536326564, 'val': 0.9238519972039024},\n",
       " {'train': 0.6099430898749105, 'val': 0.5668185352340493},\n",
       " {'train': 0.6302642027246494, 'val': 0.6036037557162195},\n",
       " {'train': 0.550001437018047, 'val': 0.46924459526660023},\n",
       " {'train': 0.6109781667128318, 'val': 0.6904009339140769},\n",
       " {'train': 0.5856537384808643, 'val': 0.8353120593180834},\n",
       " {'train': 0.5508834626020176, 'val': 0.48106388387647303},\n",
       " {'train': 0.69311364731957, 'val': 0.629294993384431},\n",
       " {'train': 0.6861136063149611, 'val': 0.7566039204390955},\n",
       " {'train': 0.6121696371455706, 'val': 0.6331751517173319},\n",
       " {'train': 0.5661686622992493, 'val': 0.42644868716920525},\n",
       " {'train': 0.5439640073507215, 'val': 0.565654813393387},\n",
       " {'train': 0.6468779767267319, 'val': 0.45658979849977355},\n",
       " {'train': 0.6395846526366398, 'val': 0.4664283248267977},\n",
       " {'train': 0.5569917316854089, 'val': 0.39352750212932663},\n",
       " {'train': 0.5989970473851234, 'val': 0.703203902479455},\n",
       " {'train': 0.5751669524971424, 'val': 0.47628083650751074},\n",
       " {'train': 0.6511023525118309, 'val': 0.60088112250633},\n",
       " {'train': 0.6319015185328567, 'val': 0.418159779330702},\n",
       " {'train': 0.40508894411967555, 'val': 0.20609888037861832},\n",
       " {'train': 0.6049325068191428, 'val': 0.5087924238667741},\n",
       " {'train': 0.6961176064893092, 'val': 0.6728913186911267},\n",
       " {'train': 0.48094284391521197, 'val': 0.3234947730970191}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "results = []\n",
    "for time_series in tqdm(ts_iterator):\n",
    "    (X_train, y_train), _, (X_test, y_test), X_scaler, y_scaler = create_ts(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                            data_preprocess=(\"log_returns\", \"normalize\"),\\\n",
    "                                            val_size=val_size, test_size=test_size)\n",
    "    X_train, X_test = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_test))\n",
    "    train_dl = Pool(X_train, label=y_train)\n",
    "    val_dl = Pool(X_test, label=y_test)\n",
    "    \n",
    "    model = CatBoostRegressor(**model_params)\n",
    "    # model.fit(train_dl, eval_set=val_dl, early_stopping_rounds=5, use_best_model=True)\n",
    "    model.fit(train_dl)\n",
    "    results.append({\"train\": MAE(y_train, model.predict(X_train)), \"test\": MAE(y_test, model.predict(X_test))})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\pure_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with QuantGAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_synth(synthetic_path):\n",
    "    ts_iterator = get_hsm_dataset(dataset_path, selected_files=f\"{dataset_path}/selected.csv\")\n",
    "\n",
    "    results = []\n",
    "    for ts_index, time_series in tqdm(enumerate(ts_iterator)):\n",
    "        synth_time_series = np.load(f\"{synthetic_path}selected{ts_index}.npy\")\n",
    "        scaler = DimUniversalStandardScaler()\n",
    "        synth_time_series = scaler.fit_transform(synth_time_series)\n",
    "        X_synth, y_synth = [], []\n",
    "        for i in range(synth_time_series.shape[0]):\n",
    "            (X, y), *_ = create_ts(synth_time_series[i].reshape(- 1, 1), synth_time_series[i].flatten(), lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                data_preprocess=(None,), val_size=0, test_size=0)\n",
    "            X_synth.append(X)\n",
    "            y_synth.append(y)\n",
    "\n",
    "        # using train and synth data\n",
    "        # X_train = np.row_stack((X_train, *X_synth))\n",
    "        # y_train = np.row_stack((y_train, *y_synth))\n",
    "        # using only synth data\n",
    "        X_synth = np.row_stack(X_synth)\n",
    "        y_synth = np.row_stack(y_synth)\n",
    "\n",
    "        \n",
    "        (X_train, y_train), _, (X_test, y_test), *_ = create_ts(time_series[[\"Close\"]], time_series[\"Close\"], lags=lags, horizon=horizon, stride=stride,\\\n",
    "                                                data_preprocess=(\"log_returns\", \"normalize\"), val_size=val_size, test_size=test_size, scaler=scaler)\n",
    "        X_train, X_test, X_synth = map(lambda x: x.reshape(x.shape[:2]), (X_train, X_test, X_synth))\n",
    "        \n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(X_synth, y_synth)\n",
    "        results.append({\"train\": MAE(y_train, model.predict(X_train)), \"test\": MAE(y_test, model.predict(X_test))})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:45, 14.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.5705976005529405, 'val': 0.495936914983925},\n",
       " {'train': 0.7906638254047553, 'val': 1.2479540067632215},\n",
       " {'train': 0.6865303624407124, 'val': 0.5589616515091492},\n",
       " {'train': 0.7183084484047211, 'val': 0.5920065674247412},\n",
       " {'train': 0.64538927090309, 'val': 0.4586054053018275},\n",
       " {'train': 0.7170679586561128, 'val': 0.7526422049527296},\n",
       " {'train': 0.7233984971455265, 'val': 0.9544777322826088},\n",
       " {'train': 0.6587851940367666, 'val': 0.531267858974961},\n",
       " {'train': 0.7518214702351398, 'val': 0.6440745649911239},\n",
       " {'train': 0.7416300429983089, 'val': 0.7444720302010077},\n",
       " {'train': 0.554201114247848, 'val': 0.5453133001746481},\n",
       " {'train': 0.6477365802668988, 'val': 0.4620950986109732},\n",
       " {'train': 0.6566237313754806, 'val': 0.650461006612295},\n",
       " {'train': 0.6681783980748504, 'val': 0.4489827860531509},\n",
       " {'train': 0.6808225869697382, 'val': 0.4732200046602029},\n",
       " {'train': 0.602612144084566, 'val': 0.4076271493397299},\n",
       " {'train': 0.6549016919492303, 'val': 0.7335707730095424},\n",
       " {'train': 0.6762183206161326, 'val': 0.5347153713233067},\n",
       " {'train': 0.700218234388386, 'val': 0.6161000091948627},\n",
       " {'train': 0.6873995468928347, 'val': 0.43388317242769614},\n",
       " {'train': 0.23414123980959628, 'val': 0.11952708652504015},\n",
       " {'train': 0.6637935361230641, 'val': 0.5552635170077036},\n",
       " {'train': 0.7407504264093686, 'val': 0.6992894731581479},\n",
       " {'train': 0.5869664906817742, 'val': 0.3742695078924564}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/QuantGAN/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\QuantGAN_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with FourierFlow synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:18, 15.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.39266954399588516, 'val': 0.3725091337596058},\n",
       " {'train': 0.5327169270857809, 'val': 0.9044217976217865},\n",
       " {'train': 0.5762583844881217, 'val': 0.5119876248562301},\n",
       " {'train': 0.588566339601027, 'val': 0.5350551802569065},\n",
       " {'train': 0.5314240151607013, 'val': 0.40696223602121684},\n",
       " {'train': 0.5733070050802087, 'val': 0.6320379544444451},\n",
       " {'train': 0.5414358874210758, 'val': 0.771274521519554},\n",
       " {'train': 0.5308209750931543, 'val': 0.4514637872366499},\n",
       " {'train': 0.6510222534537909, 'val': 0.5836922349174817},\n",
       " {'train': 0.6157591029340191, 'val': 0.6641309797338112},\n",
       " {'train': 0.588341715310258, 'val': 0.6044140241837402},\n",
       " {'train': 0.5411490473749854, 'val': 0.41200672511994774},\n",
       " {'train': 0.5292334388927556, 'val': 0.5530587776994584},\n",
       " {'train': 0.5804922537621942, 'val': 0.4188585753794068},\n",
       " {'train': 0.5761994349605177, 'val': 0.4273958347888962},\n",
       " {'train': 0.5371483760567111, 'val': 0.3801038815022171},\n",
       " {'train': 0.5511079375414307, 'val': 0.629519997618488},\n",
       " {'train': 0.5180406757918354, 'val': 0.43483315091008323},\n",
       " {'train': 0.6155737948781819, 'val': 0.5600560368995451},\n",
       " {'train': 0.5588188436298979, 'val': 0.37966851316326067},\n",
       " {'train': 0.300235459831628, 'val': 0.15171347828552556},\n",
       " {'train': 0.4782814058195393, 'val': 0.3922727419377377},\n",
       " {'train': 0.6752558849142565, 'val': 0.6531928859147603},\n",
       " {'train': 0.442013525593255, 'val': 0.3100025046946324}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/FourierFlow/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\FourierFlow_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with RealNVP synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [06:00, 15.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.4192691074775543, 'val': 0.4776051485443943},\n",
       " {'train': 0.5512715651021589, 'val': 0.9670692734367201},\n",
       " {'train': 0.5704226292157994, 'val': 0.5723821946670228},\n",
       " {'train': 0.4943670801709165, 'val': 0.5520670835215182},\n",
       " {'train': 0.406910775068723, 'val': 0.38628757516012135},\n",
       " {'train': 0.5946378997370156, 'val': 0.693233331854394},\n",
       " {'train': 0.5538422217283312, 'val': 0.8387524940423599},\n",
       " {'train': 0.5129756636136815, 'val': 0.47453442577413446},\n",
       " {'train': 0.6535407473381898, 'val': 0.6111740742505485},\n",
       " {'train': 0.5916844033456929, 'val': 0.6728116200384897},\n",
       " {'train': 0.5931179222430558, 'val': 0.6246772825282134},\n",
       " {'train': 0.5484949065926874, 'val': 0.4282977877636452},\n",
       " {'train': 0.5292970746249208, 'val': 0.5647545084844513},\n",
       " {'train': 0.6123188359375664, 'val': 0.44318650636804713},\n",
       " {'train': 0.6064087030009728, 'val': 0.45929960628791167},\n",
       " {'train': 0.5407297484561965, 'val': 0.3919202876481251},\n",
       " {'train': 0.5793005348610855, 'val': 0.684214280664782},\n",
       " {'train': 0.546312441936273, 'val': 0.47001029581875586},\n",
       " {'train': 0.6347289432811782, 'val': 0.5960802897185822},\n",
       " {'train': 0.5989234648275361, 'val': 0.41376592199658674},\n",
       " {'train': 0.4096981698377113, 'val': 0.20921401493353853},\n",
       " {'train': 0.571761924570328, 'val': 0.4839793103373297},\n",
       " {'train': 0.6825612190324195, 'val': 0.6634253249932627},\n",
       " {'train': 0.46372244864885637, 'val': 0.3280453806613545}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/RealNVP/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\RealNVP_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation with TTS GAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:51, 14.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.4033296433245175, 'val': 0.346253142740815},\n",
       " {'train': 0.44160962335612863, 'val': 0.6887987213064899},\n",
       " {'train': 0.15270834613223117, 'val': 0.15947363643142703},\n",
       " {'train': 0.1059298914431156, 'val': 0.08673123220468097},\n",
       " {'train': 0.2390187227632121, 'val': 0.23635228475615067},\n",
       " {'train': 0.7979688906555498, 'val': 0.8366779598930102},\n",
       " {'train': 0.5139242271435676, 'val': 0.6852156243025804},\n",
       " {'train': 0.7488439303803196, 'val': 0.5943480423695353},\n",
       " {'train': 0.2270093262426393, 'val': 0.19510159244237815},\n",
       " {'train': 0.22265766543676924, 'val': 0.2211849857563951},\n",
       " {'train': 1.1001916217256178, 'val': 1.0868589308255403},\n",
       " {'train': 0.9531175056031297, 'val': 0.7248833661241335},\n",
       " {'train': 0.7524001173862301, 'val': 0.7381950580076649},\n",
       " {'train': 0.5459293388254447, 'val': 0.3631415996951013},\n",
       " {'train': 0.8412013886954569, 'val': 0.5821116144416746},\n",
       " {'train': 3.7141621044628903, 'val': 3.7188648079103057},\n",
       " {'train': 0.7994655366449971, 'val': 0.8985482603995593},\n",
       " {'train': 0.3986146677453413, 'val': 0.3147644899017436},\n",
       " {'train': 0.531711876577568, 'val': 0.4674532869043445},\n",
       " {'train': 1.012060369037084, 'val': 0.6835439214402315},\n",
       " {'train': 7.075217077376028, 'val': 3.5988699157623563},\n",
       " {'train': 2.8469699684193555, 'val': 2.2902410571126914},\n",
       " {'train': 0.7233271471607332, 'val': 0.6787406180923709},\n",
       " {'train': 1.8035391767849247, 'val': 1.1472697150888118}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_synth(f\"{dataset_path}synthetic/TTS_GAN_standard/\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(f\"results\\\\TTS_GAN_synth_cbr_h{horizon}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1289e797c8b2364a1b561fc46768e8fcf8446b2e18e77ab0795c8743ff6ac10a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
